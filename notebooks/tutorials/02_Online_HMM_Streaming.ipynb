{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Hidden Markov Models for Real-Time Regime Detection\n",
    "\n",
    "This notebook demonstrates how to use Online Hidden Markov Models for real-time market regime detection and streaming data processing.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will understand:\n",
    "1. The differences between batch and online HMMs\n",
    "2. How to configure and initialize an Online HMM\n",
    "3. Real-time data processing and streaming updates\n",
    "4. Adaptive parameter estimation with forgetting factors\n",
    "5. Building real-time trading systems with Online HMMs\n",
    "6. Performance monitoring and model adaptation\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of \"Introduction to HMM Finance\" tutorial (recommended)\n",
    "- Understanding of basic HMM concepts\n",
    "- Familiarity with streaming data concepts\n",
    "\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our HMM models\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from hidden_regime.models.base_hmm import HiddenMarkovModel\n",
    "from hidden_regime.models.online_hmm import OnlineHMM, OnlineHMMConfig\n",
    "from hidden_regime.data.loader import DataLoader\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Online vs Batch Learning\n",
    "\n",
    "### Batch HMM (Traditional Approach)\n",
    "- **Full dataset training**: Requires entire historical dataset\n",
    "- **Parameter stability**: Fixed parameters after training\n",
    "- **Computational cost**: O(T²) for Baum-Welch algorithm\n",
    "- **Historical revision**: Past regime labels change with new data\n",
    "- **Use case**: Historical analysis, backtesting\n",
    "\n",
    "### Online HMM (Streaming Approach)\n",
    "- **Incremental learning**: Updates with each new observation\n",
    "- **Adaptive parameters**: Evolves with changing market conditions\n",
    "- **Computational efficiency**: O(1) per new observation\n",
    "- **Temporal consistency**: Stable historical classifications\n",
    "- **Use case**: Real-time trading, live monitoring\n",
    "\n",
    "Let's compare both approaches side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data for comparison\n",
    "print(\"📊 Loading market data for comparison...\")\n",
    "\n",
    "# Download data for comparison\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "data['Log_Return'] = np.log(data['Adj Close'] / data['Adj Close'].shift(1))\n",
    "data = data.dropna()\n",
    "\n",
    "returns = data['Log_Return'].values\n",
    "print(f\"✅ Downloaded {len(data)} days of {ticker} data\")\n",
    "print(f\"Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "\n",
    "# Split data for comparison\n",
    "split_point = len(returns) // 2\n",
    "train_returns = returns[:split_point]\n",
    "test_returns = returns[split_point:]\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training period: {split_point} observations\")\n",
    "print(f\"  Testing period: {len(test_returns)} observations\")\n",
    "\n",
    "# Demonstrate the difference in computational requirements\n",
    "print(f\"\\n⚡ Computational Complexity Comparison:\")\n",
    "print(f\"  Batch HMM: O(T²) = O({len(returns)}²) = ~{len(returns)**2:,} operations\")\n",
    "print(f\"  Online HMM: O(1) per observation = {len(test_returns)} total operations\")\n",
    "print(f\"  Efficiency gain: ~{(len(returns)**2) / len(test_returns):,.0f}x faster for streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring Online HMM\n",
    "\n",
    "The Online HMM requires careful configuration of several key parameters that control its adaptation behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Online HMM with detailed explanations\n",
    "print(\"⚙️ CONFIGURING ONLINE HMM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create configuration with explanations\n",
    "config = OnlineHMMConfig(\n",
    "    # Model structure\n",
    "    n_states=3,              # Number of market regimes (Bull, Bear, Sideways)\n",
    "    n_features=1,            # Number of features (just returns for now)\n",
    "    \n",
    "    # Learning parameters\n",
    "    forgetting_factor=0.995,  # How quickly to forget old data (0.99-0.999)\n",
    "    adaptation_rate=0.05,     # How quickly to adapt parameters (0.01-0.1)\n",
    "    \n",
    "    # Memory management\n",
    "    window_size=252,          # Rolling window size (1 year of trading days)\n",
    "    min_observations=50,      # Minimum observations before making predictions\n",
    "    \n",
    "    # Numerical stability\n",
    "    regularization=1e-6,      # Regularization for numerical stability\n",
    "    convergence_threshold=1e-4, # Convergence threshold for initialization\n",
    "    max_iterations=100,       # Maximum iterations for initialization\n",
    "    \n",
    "    # Random seed for reproducibility\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"📋 Configuration Summary:\")\n",
    "print(f\"  Model Structure:\")\n",
    "print(f\"    - States: {config.n_states}\")\n",
    "print(f\"    - Features: {config.n_features}\")\n",
    "print(f\"  Learning Parameters:\")\n",
    "print(f\"    - Forgetting factor: {config.forgetting_factor} (half-life: {np.log(0.5)/np.log(config.forgetting_factor):.0f} days)\")\n",
    "print(f\"    - Adaptation rate: {config.adaptation_rate}\")\n",
    "print(f\"  Memory Management:\")\n",
    "print(f\"    - Window size: {config.window_size} observations\")\n",
    "print(f\"    - Minimum observations: {config.min_observations}\")\n",
    "\n",
    "print(f\"\\n🎯 Parameter Interpretation:\")\n",
    "print(f\"  Forgetting Factor ({config.forgetting_factor}):\")\n",
    "print(f\"    - High value (>0.99): Long memory, slow adaptation\")\n",
    "print(f\"    - Low value (<0.95): Short memory, fast adaptation\")\n",
    "print(f\"    - Current setting: Balanced for financial markets\")\n",
    "print(f\"  Adaptation Rate ({config.adaptation_rate}):\")\n",
    "print(f\"    - High value (>0.1): Quick parameter updates, less stable\")\n",
    "print(f\"    - Low value (<0.01): Slow parameter updates, more stable\")\n",
    "print(f\"    - Current setting: Conservative for regime stability\")\n",
    "\n",
    "# Initialize the Online HMM\n",
    "online_hmm = OnlineHMM(config)\n",
    "print(f\"\\n✅ Online HMM initialized and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Training and Warm-up Period\n",
    "\n",
    "Online HMMs need an initial training period to establish baseline parameters before they can adapt incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training phase\n",
    "print(\"🚀 INITIAL TRAINING PHASE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Use first portion of data for initial training\n",
    "init_size = max(config.min_observations, 100)  # Ensure we have enough data\n",
    "init_data = train_returns[:init_size].reshape(-1, 1)\n",
    "\n",
    "print(f\"Training with {len(init_data)} initial observations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Fit the model with initial data\n",
    "    online_hmm.fit(init_data)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"✅ Initial training completed in {training_time:.3f} seconds\")\n",
    "    \n",
    "    # Display initial model parameters\n",
    "    print(f\"\\n📊 Initial Model Parameters:\")\n",
    "    \n",
    "    # Get current parameters\n",
    "    try:\n",
    "        current_params = online_hmm.get_parameters()\n",
    "        \n",
    "        print(f\"  Transition Matrix:\")\n",
    "        for i, row in enumerate(current_params['transition_matrix']):\n",
    "            print(f\"    State {i}: [{', '.join([f'{p:.3f}' for p in row])}]\")\n",
    "        \n",
    "        print(f\"  Emission Parameters:\")\n",
    "        for i, (mean, cov) in enumerate(zip(current_params['means'], current_params['covariances'])):\n",
    "            std = np.sqrt(cov[0, 0])\n",
    "            print(f\"    State {i}: μ={mean[0]:.4f}, σ={std:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Parameter extraction not available: {e}\")\n",
    "    \n",
    "    # Test initial prediction capability\n",
    "    test_obs = np.array([[train_returns[init_size]]])\n",
    "    regime_info = online_hmm.get_current_regime_info()\n",
    "    \n",
    "    print(f\"\\n🎯 Initial Regime Detection Test:\")\n",
    "    print(f\"  Current regime: {regime_info.get('most_likely_regime', 'Unknown')}\")\n",
    "    print(f\"  Confidence: {regime_info.get('confidence', 0):.2%}\")\n",
    "    \n",
    "    regime_probs = regime_info.get('regime_probabilities', [])\n",
    "    if regime_probs:\n",
    "        for i, prob in enumerate(regime_probs):\n",
    "            print(f\"  State {i} probability: {prob:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Initial training failed: {e}\")\n",
    "    print(f\"This might be due to insufficient data or numerical issues\")\n",
    "    print(f\"Consider adjusting configuration parameters\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Data Processing\n",
    "\n",
    "Now let's demonstrate the core capability of Online HMMs: processing streaming data one observation at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real-time streaming data processing\n",
    "print(\"🌊 STREAMING DATA PROCESSING SIMULATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare streaming simulation\n",
    "streaming_start = init_size\n",
    "streaming_data = train_returns[streaming_start:]\n",
    "streaming_dates = data.index[streaming_start:streaming_start + len(streaming_data)]\n",
    "\n",
    "print(f\"Simulating streaming processing of {len(streaming_data)} observations...\")\n",
    "print(f\"Processing period: {streaming_dates[0].date()} to {streaming_dates[-1].date()}\")\n",
    "\n",
    "# Storage for streaming results\n",
    "streaming_results = []\n",
    "processing_times = []\n",
    "parameter_evolution = {'means': [], 'covariances': [], 'transitions': []}\n",
    "\n",
    "# Process each observation\n",
    "for i, (new_return, date) in enumerate(zip(streaming_data[:100], streaming_dates[:100])):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Update model with new observation\n",
    "        online_hmm.update(new_return)\n",
    "        \n",
    "        # Get current regime information\n",
    "        regime_info = online_hmm.get_current_regime_info()\n",
    "        \n",
    "        # Record processing time\n",
    "        processing_time = time.time() - start_time\n",
    "        processing_times.append(processing_time)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'date': date,\n",
    "            'return': new_return,\n",
    "            'regime': regime_info.get('most_likely_regime', -1),\n",
    "            'confidence': regime_info.get('confidence', 0),\n",
    "            'processing_time_ms': processing_time * 1000,\n",
    "            'regime_probs': regime_info.get('regime_probabilities', [0, 0, 0])\n",
    "        }\n",
    "        streaming_results.append(result)\n",
    "        \n",
    "        # Store parameter evolution (every 10 observations to save memory)\n",
    "        if i % 10 == 0:\n",
    "            try:\n",
    "                params = online_hmm.get_parameters()\n",
    "                parameter_evolution['means'].append(params['means'].copy())\n",
    "                parameter_evolution['covariances'].append(params['covariances'].copy())\n",
    "                parameter_evolution['transitions'].append(params['transition_matrix'].copy())\n",
    "            except:\n",
    "                pass  # Parameters might not be available\n",
    "        \n",
    "        # Print progress every 20 observations\n",
    "        if (i + 1) % 20 == 0:\n",
    "            avg_time = np.mean(processing_times[-20:]) * 1000\n",
    "            regime = regime_info.get('most_likely_regime', 'Unknown')\n",
    "            confidence = regime_info.get('confidence', 0)\n",
    "            print(f\"  Processed {i+1:3d} obs | {date.strftime('%Y-%m-%d')} | \"\n",
    "                  f\"Regime: {regime} ({confidence:.1%}) | Avg: {avg_time:.2f}ms\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing observation {i}: {e}\")\n",
    "        break\n",
    "\n",
    "# Performance summary\n",
    "if processing_times:\n",
    "    print(f\"\\n📊 STREAMING PERFORMANCE SUMMARY:\")\n",
    "    print(f\"  Total observations processed: {len(processing_times)}\")\n",
    "    print(f\"  Average processing time: {np.mean(processing_times)*1000:.2f} ms\")\n",
    "    print(f\"  Median processing time: {np.median(processing_times)*1000:.2f} ms\")\n",
    "    print(f\"  95th percentile: {np.percentile(processing_times, 95)*1000:.2f} ms\")\n",
    "    print(f\"  Maximum processing time: {np.max(processing_times)*1000:.2f} ms\")\n",
    "    \n",
    "    # Throughput calculation\n",
    "    observations_per_second = 1 / np.mean(processing_times)\n",
    "    print(f\"  Theoretical throughput: {observations_per_second:.0f} obs/sec\")\n",
    "    \n",
    "    if observations_per_second > 1000:\n",
    "        print(f\"  ✅ Excellent performance for real-time trading!\")\n",
    "    elif observations_per_second > 100:\n",
    "        print(f\"  ✅ Good performance for most applications\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ May need optimization for high-frequency applications\")\n",
    "\n",
    "print(f\"\\n✅ Streaming simulation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Streaming Results\n",
    "\n",
    "Let's analyze the results from our streaming simulation to understand how the Online HMM adapts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "if streaming_results:\n",
    "    results_df = pd.DataFrame(streaming_results)\n",
    "    results_df.set_index('date', inplace=True)\n",
    "    \n",
    "    print(f\"📈 STREAMING RESULTS ANALYSIS\")\n",
    "    print(f\"=\" * 40)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Analysis period: {len(results_df)} observations\")\n",
    "    print(f\"Date range: {results_df.index[0].date()} to {results_df.index[-1].date()}\")\n",
    "    \n",
    "    # Regime distribution\n",
    "    regime_counts = results_df['regime'].value_counts().sort_index()\n",
    "    print(f\"\\nRegime Distribution:\")\n",
    "    for regime, count in regime_counts.items():\n",
    "        percentage = count / len(results_df) * 100\n",
    "        print(f\"  State {regime}: {count} days ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Confidence statistics\n",
    "    avg_confidence = results_df['confidence'].mean()\n",
    "    high_confidence_pct = (results_df['confidence'] > 0.7).mean()\n",
    "    low_confidence_pct = (results_df['confidence'] < 0.5).mean()\n",
    "    \n",
    "    print(f\"\\nConfidence Statistics:\")\n",
    "    print(f\"  Average confidence: {avg_confidence:.1%}\")\n",
    "    print(f\"  High confidence days (>70%): {high_confidence_pct:.1%}\")\n",
    "    print(f\"  Low confidence days (<50%): {low_confidence_pct:.1%}\")\n",
    "    \n",
    "    # Performance statistics\n",
    "    avg_processing_time = results_df['processing_time_ms'].mean()\n",
    "    max_processing_time = results_df['processing_time_ms'].max()\n",
    "    \n",
    "    print(f\"\\nProcessing Performance:\")\n",
    "    print(f\"  Average processing time: {avg_processing_time:.2f} ms\")\n",
    "    print(f\"  Maximum processing time: {max_processing_time:.2f} ms\")\n",
    "    \n",
    "    # Check for regime switches\n",
    "    regime_switches = (results_df['regime'] != results_df['regime'].shift(1)).sum() - 1\n",
    "    print(f\"\\nRegime Dynamics:\")\n",
    "    print(f\"  Total regime switches: {regime_switches}\")\n",
    "    print(f\"  Average regime duration: {len(results_df) / (regime_switches + 1):.1f} days\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No streaming results to analyze\")\n",
    "    results_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize streaming results\n",
    "if results_df is not None and len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 16))\n",
    "    fig.suptitle('Online HMM Streaming Analysis Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Returns colored by regime\n",
    "    colors = ['red', 'orange', 'green']\n",
    "    for regime in results_df['regime'].unique():\n",
    "        if regime >= 0:  # Valid regime\n",
    "            mask = results_df['regime'] == regime\n",
    "            if mask.any():\n",
    "                axes[0].scatter(results_df.index[mask], results_df['return'][mask], \n",
    "                               c=colors[int(regime) % len(colors)], alpha=0.6, s=20, \n",
    "                               label=f'State {int(regime)}')\n",
    "    \n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_title('Returns Colored by Detected Regime')\n",
    "    axes[0].set_ylabel('Daily Return')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Regime probabilities over time\n",
    "    if len(results_df['regime_probs'].iloc[0]) >= 3:\n",
    "        # Extract probability arrays\n",
    "        prob_array = np.array(results_df['regime_probs'].tolist())\n",
    "        \n",
    "        # Stack probabilities\n",
    "        axes[1].fill_between(results_df.index, 0, prob_array[:, 0], \n",
    "                            color='red', alpha=0.7, label='State 0')\n",
    "        axes[1].fill_between(results_df.index, prob_array[:, 0], \n",
    "                            prob_array[:, 0] + prob_array[:, 1], \n",
    "                            color='orange', alpha=0.7, label='State 1')\n",
    "        axes[1].fill_between(results_df.index, prob_array[:, 0] + prob_array[:, 1], 1,\n",
    "                            color='green', alpha=0.7, label='State 2')\n",
    "        \n",
    "        axes[1].set_title('Regime Probabilities Over Time')\n",
    "        axes[1].set_ylabel('Probability')\n",
    "        axes[1].set_ylim(0, 1)\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Confidence over time\n",
    "    axes[2].plot(results_df.index, results_df['confidence'], 'navy', linewidth=1, alpha=0.8)\n",
    "    axes[2].axhline(y=0.7, color='green', linestyle='--', alpha=0.7, label='High Confidence')\n",
    "    axes[2].axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='Low Confidence')\n",
    "    axes[2].fill_between(results_df.index, 0.7, 1, alpha=0.2, color='green')\n",
    "    axes[2].fill_between(results_df.index, 0, 0.5, alpha=0.2, color='red')\n",
    "    \n",
    "    axes[2].set_title('Classification Confidence Over Time')\n",
    "    axes[2].set_ylabel('Confidence')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Processing time performance\n",
    "    axes[3].plot(results_df.index, results_df['processing_time_ms'], 'purple', alpha=0.7, linewidth=1)\n",
    "    axes[3].axhline(y=results_df['processing_time_ms'].mean(), color='red', \n",
    "                   linestyle='-', alpha=0.8, label=f'Average: {results_df[\"processing_time_ms\"].mean():.2f}ms')\n",
    "    axes[3].axhline(y=results_df['processing_time_ms'].quantile(0.95), color='orange', \n",
    "                   linestyle='--', alpha=0.8, label=f'95th percentile: {results_df[\"processing_time_ms\"].quantile(0.95):.2f}ms')\n",
    "    \n",
    "    axes[3].set_title('Processing Time Performance')\n",
    "    axes[3].set_ylabel('Processing Time (ms)')\n",
    "    axes[3].set_xlabel('Date')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional analysis: regime transitions\n",
    "    print(f\"\\n🔄 REGIME TRANSITION ANALYSIS:\")\n",
    "    print(f\"=\" * 40)\n",
    "    \n",
    "    # Find regime switches\n",
    "    regime_changes = results_df[results_df['regime'] != results_df['regime'].shift(1)].copy()\n",
    "    regime_changes = regime_changes.iloc[1:]  # Remove first observation\n",
    "    \n",
    "    if len(regime_changes) > 0:\n",
    "        print(f\"Total regime switches detected: {len(regime_changes)}\")\n",
    "        print(f\"\\nMajor regime transitions:\")\n",
    "        \n",
    "        for i, (date, row) in enumerate(regime_changes.head(10).iterrows()):\n",
    "            prev_regime = results_df.loc[:date].iloc[-2]['regime']\n",
    "            new_regime = row['regime']\n",
    "            confidence = row['confidence']\n",
    "            return_val = row['return']\n",
    "            \n",
    "            print(f\"  {date.strftime('%Y-%m-%d')}: State {int(prev_regime)} → State {int(new_regime)} \"\n",
    "                  f\"(conf: {confidence:.1%}, return: {return_val:.3f})\")\n",
    "    else:\n",
    "        print(\"No regime switches detected in this period\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Evolution Analysis\n",
    "\n",
    "One of the key advantages of Online HMMs is their ability to adapt parameters over time. Let's examine how model parameters evolve during streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze parameter evolution\n",
    "print(f\"🔬 PARAMETER EVOLUTION ANALYSIS\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "if parameter_evolution['means'] and len(parameter_evolution['means']) > 1:\n",
    "    print(f\"Parameter snapshots collected: {len(parameter_evolution['means'])}\")\n",
    "    \n",
    "    # Extract evolution data\n",
    "    means_evolution = np.array(parameter_evolution['means'])\n",
    "    covariances_evolution = np.array(parameter_evolution['covariances'])\n",
    "    transitions_evolution = np.array(parameter_evolution['transitions'])\n",
    "    \n",
    "    print(f\"Shape of means evolution: {means_evolution.shape}\")\n",
    "    print(f\"Shape of covariances evolution: {covariances_evolution.shape}\")\n",
    "    print(f\"Shape of transitions evolution: {transitions_evolution.shape}\")\n",
    "    \n",
    "    # Analyze parameter stability\n",
    "    print(f\"\\n📊 Parameter Stability Analysis:\")\n",
    "    \n",
    "    # Mean parameters evolution\n",
    "    for state in range(means_evolution.shape[1]):\n",
    "        state_means = means_evolution[:, state, 0]  # Extract mean values\n",
    "        initial_mean = state_means[0]\n",
    "        final_mean = state_means[-1]\n",
    "        mean_change = final_mean - initial_mean\n",
    "        mean_volatility = np.std(state_means)\n",
    "        \n",
    "        print(f\"  State {state} Mean Evolution:\")\n",
    "        print(f\"    Initial: {initial_mean:.5f}\")\n",
    "        print(f\"    Final: {final_mean:.5f}\")\n",
    "        print(f\"    Change: {mean_change:.5f}\")\n",
    "        print(f\"    Volatility: {mean_volatility:.5f}\")\n",
    "    \n",
    "    # Variance parameters evolution\n",
    "    print(f\"\\n  Variance Evolution:\")\n",
    "    for state in range(covariances_evolution.shape[1]):\n",
    "        state_vars = covariances_evolution[:, state, 0, 0]  # Extract variance values\n",
    "        state_stds = np.sqrt(state_vars)\n",
    "        initial_std = state_stds[0]\n",
    "        final_std = state_stds[-1]\n",
    "        std_change = final_std - initial_std\n",
    "        \n",
    "        print(f\"    State {state} Std Evolution:\")\n",
    "        print(f\"      Initial: {initial_std:.5f}\")\n",
    "        print(f\"      Final: {final_std:.5f}\")\n",
    "        print(f\"      Change: {std_change:.5f}\")\n",
    "    \n",
    "    # Visualize parameter evolution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Online HMM Parameter Evolution', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot mean evolution\n",
    "    for state in range(means_evolution.shape[1]):\n",
    "        axes[0, 0].plot(means_evolution[:, state, 0], \n",
    "                       label=f'State {state}', linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    axes[0, 0].set_title('Mean Parameters Evolution')\n",
    "    axes[0, 0].set_xlabel('Update Step')\n",
    "    axes[0, 0].set_ylabel('Mean Return')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot standard deviation evolution\n",
    "    for state in range(covariances_evolution.shape[1]):\n",
    "        state_stds = np.sqrt(covariances_evolution[:, state, 0, 0])\n",
    "        axes[0, 1].plot(state_stds, \n",
    "                       label=f'State {state}', linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    axes[0, 1].set_title('Standard Deviation Evolution')\n",
    "    axes[0, 1].set_xlabel('Update Step')\n",
    "    axes[0, 1].set_ylabel('Standard Deviation')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot transition probabilities evolution (diagonal elements)\n",
    "    for state in range(transitions_evolution.shape[1]):\n",
    "        persistence_probs = transitions_evolution[:, state, state]\n",
    "        axes[1, 0].plot(persistence_probs, \n",
    "                       label=f'State {state}', linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    axes[1, 0].set_title('State Persistence Probabilities')\n",
    "    axes[1, 0].set_xlabel('Update Step')\n",
    "    axes[1, 0].set_ylabel('P(stay in state)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # Plot parameter change magnitude over time\n",
    "    if len(means_evolution) > 1:\n",
    "        mean_changes = []\n",
    "        for i in range(1, len(means_evolution)):\n",
    "            change_magnitude = np.linalg.norm(means_evolution[i] - means_evolution[i-1])\n",
    "            mean_changes.append(change_magnitude)\n",
    "        \n",
    "        axes[1, 1].plot(mean_changes, 'purple', linewidth=2, marker='o', markersize=3)\n",
    "        axes[1, 1].set_title('Parameter Change Magnitude')\n",
    "        axes[1, 1].set_xlabel('Update Step')\n",
    "        axes[1, 1].set_ylabel('Change Magnitude')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        if len(mean_changes) > 2:\n",
    "            z = np.polyfit(range(len(mean_changes)), mean_changes, 1)\n",
    "            p = np.poly1d(z)\n",
    "            axes[1, 1].plot(range(len(mean_changes)), p(range(len(mean_changes))), \n",
    "                           \"r--\", alpha=0.8, label=f'Trend (slope: {z[0]:.6f})')\n",
    "            axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Stability assessment\n",
    "    if len(mean_changes) > 5:\n",
    "        recent_stability = np.mean(mean_changes[-5:])\n",
    "        initial_stability = np.mean(mean_changes[:5])\n",
    "        \n",
    "        print(f\"\\n📈 Adaptation Assessment:\")\n",
    "        print(f\"  Initial adaptation rate: {initial_stability:.6f}\")\n",
    "        print(f\"  Recent adaptation rate: {recent_stability:.6f}\")\n",
    "        \n",
    "        if recent_stability < initial_stability * 0.5:\n",
    "            print(f\"  ✅ Parameters are stabilizing over time\")\n",
    "        elif recent_stability > initial_stability * 2:\n",
    "            print(f\"  ⚠️ Parameters are becoming more volatile\")\n",
    "        else:\n",
    "            print(f\"  ✅ Parameters show consistent adaptation\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Insufficient parameter evolution data collected\")\n",
    "    print(\"This could be due to:\")\n",
    "    print(\"  • Short streaming period\")\n",
    "    print(\"  • Parameter extraction issues\")\n",
    "    print(\"  • Model initialization problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Online vs Batch HMM Performance\n",
    "\n",
    "Let's compare the Online HMM with a traditional Batch HMM to understand the trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Online vs Batch HMM\n",
    "print(f\"⚖️ ONLINE vs BATCH HMM COMPARISON\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "# Use test data for comparison\n",
    "comparison_data = test_returns[:100]  # Limit for speed\n",
    "comparison_dates = data.index[split_point:split_point + len(comparison_data)]\n",
    "\n",
    "print(f\"Comparison dataset: {len(comparison_data)} observations\")\n",
    "print(f\"Period: {comparison_dates[0].date()} to {comparison_dates[-1].date()}\")\n",
    "\n",
    "# Initialize Batch HMM\n",
    "print(f\"\\n🔄 Training Batch HMM...\")\n",
    "batch_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    batch_hmm = HiddenMarkovModel(n_states=3, random_state=42)\n",
    "    \n",
    "    # Train on all available data (train + comparison)\n",
    "    all_training_data = np.concatenate([train_returns, comparison_data]).reshape(-1, 1)\n",
    "    batch_hmm.fit(all_training_data)\n",
    "    \n",
    "    batch_training_time = time.time() - batch_start_time\n",
    "    print(f\"✅ Batch HMM training completed in {batch_training_time:.3f} seconds\")\n",
    "    \n",
    "    # Get batch predictions\n",
    "    batch_states = batch_hmm.predict(comparison_data.reshape(-1, 1))\n",
    "    batch_probs = batch_hmm.predict_proba(comparison_data.reshape(-1, 1))\n",
    "    \n",
    "    print(f\"✅ Batch HMM predictions completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Batch HMM training failed: {e}\")\n",
    "    batch_hmm = None\n",
    "    batch_states = None\n",
    "    batch_probs = None\n",
    "\n",
    "# Process same data with Online HMM (continue from previous state)\n",
    "print(f\"\\n🌊 Processing with Online HMM...\")\n",
    "online_start_time = time.time()\n",
    "\n",
    "online_states = []\n",
    "online_probs = []\n",
    "online_processing_times = []\n",
    "\n",
    "for new_return in comparison_data:\n",
    "    obs_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        online_hmm.update(new_return)\n",
    "        regime_info = online_hmm.get_current_regime_info()\n",
    "        \n",
    "        online_states.append(regime_info.get('most_likely_regime', -1))\n",
    "        online_probs.append(regime_info.get('regime_probabilities', [0, 0, 0]))\n",
    "        \n",
    "        obs_time = time.time() - obs_start_time\n",
    "        online_processing_times.append(obs_time)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in online processing: {e}\")\n",
    "        online_states.append(-1)\n",
    "        online_probs.append([0, 0, 0])\n",
    "        online_processing_times.append(0)\n",
    "\n",
    "online_total_time = time.time() - online_start_time\n",
    "print(f\"✅ Online HMM processing completed in {online_total_time:.3f} seconds\")\n",
    "\n",
    "# Performance comparison\n",
    "if batch_states is not None and online_states:\n",
    "    print(f\"\\n📊 PERFORMANCE COMPARISON:\")\n",
    "    print(f\"=\" * 30)\n",
    "    \n",
    "    print(f\"Training/Processing Time:\")\n",
    "    print(f\"  Batch HMM: {batch_training_time:.3f} seconds (one-time training)\")\n",
    "    print(f\"  Online HMM: {online_total_time:.3f} seconds (incremental processing)\")\n",
    "    print(f\"  Speed ratio: {batch_training_time / online_total_time:.1f}x\")\n",
    "    \n",
    "    print(f\"\\nPer-observation Processing:\")\n",
    "    avg_online_time = np.mean(online_processing_times) * 1000\n",
    "    batch_per_obs = (batch_training_time / len(comparison_data)) * 1000\n",
    "    print(f\"  Batch HMM: {batch_per_obs:.2f} ms per observation (amortized)\")\n",
    "    print(f\"  Online HMM: {avg_online_time:.2f} ms per observation\")\n",
    "    \n",
    "    # Agreement analysis\n",
    "    online_states_array = np.array(online_states)\n",
    "    valid_mask = (online_states_array >= 0) & (batch_states >= 0)\n",
    "    \n",
    "    if valid_mask.sum() > 0:\n",
    "        agreement = (online_states_array[valid_mask] == batch_states[valid_mask]).mean()\n",
    "        print(f\"\\nRegime Classification Agreement:\")\n",
    "        print(f\"  Agreement rate: {agreement:.1%}\")\n",
    "        \n",
    "        if agreement > 0.8:\n",
    "            print(f\"  ✅ High agreement - Online HMM is consistent\")\n",
    "        elif agreement > 0.6:\n",
    "            print(f\"  ⚠️ Moderate agreement - Some differences expected\")\n",
    "        else:\n",
    "            print(f\"  ❌ Low agreement - Check model configuration\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(batch_states[valid_mask], online_states_array[valid_mask])\n",
    "        print(f\"\\nConfusion Matrix (Batch vs Online):\")\n",
    "        print(f\"     Online→ {' '.join([f'{i:3d}' for i in range(cm.shape[1])])}\")\n",
    "        for i, row in enumerate(cm):\n",
    "            print(f\"Batch {i}: [{' '.join([f'{val:3d}' for val in row])}]\")\n",
    "\n",
    "# Memory usage comparison\n",
    "print(f\"\\n💾 MEMORY USAGE COMPARISON:\")\n",
    "print(f\"=\" * 30)\n",
    "print(f\"Batch HMM:\")\n",
    "print(f\"  • Stores entire dataset: {len(all_training_data) * 8} bytes\")\n",
    "print(f\"  • Model parameters: ~{3*3 + 3*2} parameters\")\n",
    "print(f\"  • Total memory: High (scales with data size)\")\n",
    "print(f\"\\nOnline HMM:\")\n",
    "print(f\"  • Rolling window: {config.window_size * 8} bytes\")\n",
    "print(f\"  • Sufficient statistics: Fixed size\")\n",
    "print(f\"  • Total memory: Low (constant size)\")\n",
    "\n",
    "print(f\"\\n✅ Comparison completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "if batch_states is not None and online_states and len(online_states) > 0:\n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'date': comparison_dates[:len(online_states)],\n",
    "        'return': comparison_data[:len(online_states)],\n",
    "        'batch_regime': batch_states[:len(online_states)],\n",
    "        'online_regime': online_states\n",
    "    })\n",
    "    comparison_df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "    fig.suptitle('Online vs Batch HMM Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    colors = ['red', 'orange', 'green']\n",
    "    \n",
    "    # Plot 1: Batch HMM results\n",
    "    for regime in np.unique(comparison_df['batch_regime']):\n",
    "        if regime >= 0:\n",
    "            mask = comparison_df['batch_regime'] == regime\n",
    "            if mask.any():\n",
    "                axes[0].scatter(comparison_df.index[mask], comparison_df['return'][mask], \n",
    "                               c=colors[int(regime) % len(colors)], alpha=0.6, s=20, \n",
    "                               label=f'State {int(regime)}')\n",
    "    \n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_title('Batch HMM: Returns Colored by Regime')\n",
    "    axes[0].set_ylabel('Daily Return')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Online HMM results\n",
    "    for regime in np.unique(comparison_df['online_regime']):\n",
    "        if regime >= 0:\n",
    "            mask = comparison_df['online_regime'] == regime\n",
    "            if mask.any():\n",
    "                axes[1].scatter(comparison_df.index[mask], comparison_df['return'][mask], \n",
    "                               c=colors[int(regime) % len(colors)], alpha=0.6, s=20, \n",
    "                               label=f'State {int(regime)}')\n",
    "    \n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_title('Online HMM: Returns Colored by Regime')\n",
    "    axes[1].set_ylabel('Daily Return')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Agreement analysis\n",
    "    agreement_mask = comparison_df['batch_regime'] == comparison_df['online_regime']\n",
    "    disagreement_mask = ~agreement_mask\n",
    "    \n",
    "    if agreement_mask.any():\n",
    "        axes[2].scatter(comparison_df.index[agreement_mask], comparison_df['return'][agreement_mask], \n",
    "                       c='green', alpha=0.7, s=20, label='Agreement')\n",
    "    \n",
    "    if disagreement_mask.any():\n",
    "        axes[2].scatter(comparison_df.index[disagreement_mask], comparison_df['return'][disagreement_mask], \n",
    "                       c='red', alpha=0.7, s=30, marker='x', label='Disagreement')\n",
    "    \n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_title('Model Agreement Analysis')\n",
    "    axes[2].set_ylabel('Daily Return')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    agreement_rate = agreement_mask.mean()\n",
    "    print(f\"\\n📊 VISUAL COMPARISON SUMMARY:\")\n",
    "    print(f\"Total observations: {len(comparison_df)}\")\n",
    "    print(f\"Agreement rate: {agreement_rate:.1%}\")\n",
    "    print(f\"Disagreement points: {disagreement_mask.sum()}\")\n",
    "    \n",
    "    if disagreement_mask.any():\n",
    "        print(f\"\\nDisagreement analysis:\")\n",
    "        disagreement_returns = comparison_df.loc[disagreement_mask, 'return']\n",
    "        print(f\"  Average return on disagreement days: {disagreement_returns.mean():.4f}\")\n",
    "        print(f\"  Volatility on disagreement days: {disagreement_returns.std():.4f}\")\n",
    "        print(f\"  This suggests disagreements occur during: {'high volatility' if disagreement_returns.std() > comparison_df['return'].std() else 'normal'} periods\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create comparison visualization - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-Time Trading Application\n",
    "\n",
    "Let's build a simple real-time trading system using our Online HMM for regime-based position sizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time trading system simulation\n",
    "print(f\"💼 REAL-TIME TRADING SYSTEM SIMULATION\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "class OnlineHMMTradingSystem:\n",
    "    \"\"\"\n",
    "    Real-time trading system using Online HMM for regime detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, online_hmm, initial_capital=100000):\n",
    "        self.hmm = online_hmm\n",
    "        self.initial_capital = initial_capital\n",
    "        self.current_capital = initial_capital\n",
    "        self.current_position = 0.0  # Current position (-1 to 1)\n",
    "        self.trade_history = []\n",
    "        self.portfolio_history = []\n",
    "        \n",
    "        # Trading parameters\n",
    "        self.regime_positions = {\n",
    "            0: -0.5,   # Bear market: Short position\n",
    "            1: 0.0,    # Sideways: Neutral\n",
    "            2: 1.0     # Bull market: Long position\n",
    "        }\n",
    "        \n",
    "        self.confidence_threshold = 0.6  # Minimum confidence for trading\n",
    "        self.max_position_size = 1.0     # Maximum position size\n",
    "        \n",
    "    def get_target_position(self, regime_info, price):\n",
    "        \"\"\"\n",
    "        Calculate target position based on regime detection\n",
    "        \"\"\"\n",
    "        regime = regime_info.get('most_likely_regime', 1)\n",
    "        confidence = regime_info.get('confidence', 0)\n",
    "        \n",
    "        # Base position from regime\n",
    "        base_position = self.regime_positions.get(regime, 0.0)\n",
    "        \n",
    "        # Scale by confidence\n",
    "        if confidence < self.confidence_threshold:\n",
    "            # Reduce position when uncertain\n",
    "            position_scale = confidence / self.confidence_threshold * 0.5\n",
    "        else:\n",
    "            position_scale = confidence\n",
    "        \n",
    "        target_position = base_position * position_scale * self.max_position_size\n",
    "        \n",
    "        return target_position\n",
    "    \n",
    "    def execute_trade(self, date, price, return_val):\n",
    "        \"\"\"\n",
    "        Execute trading decision based on current market state\n",
    "        \"\"\"\n",
    "        # Update HMM with new return\n",
    "        self.hmm.update(return_val)\n",
    "        \n",
    "        # Get regime information\n",
    "        regime_info = self.hmm.get_current_regime_info()\n",
    "        \n",
    "        # Calculate target position\n",
    "        target_position = self.get_target_position(regime_info, price)\n",
    "        \n",
    "        # Execute trade if position change is significant\n",
    "        position_change = target_position - self.current_position\n",
    "        \n",
    "        if abs(position_change) > 0.05:  # 5% threshold for trading\n",
    "            trade = {\n",
    "                'date': date,\n",
    "                'price': price,\n",
    "                'return': return_val,\n",
    "                'old_position': self.current_position,\n",
    "                'new_position': target_position,\n",
    "                'position_change': position_change,\n",
    "                'regime': regime_info.get('most_likely_regime', -1),\n",
    "                'confidence': regime_info.get('confidence', 0),\n",
    "                'capital_before': self.current_capital\n",
    "            }\n",
    "            \n",
    "            self.current_position = target_position\n",
    "            self.trade_history.append(trade)\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        # Simplified: assume we can hold fractional positions\n",
    "        portfolio_return = self.current_position * return_val\n",
    "        self.current_capital *= (1 + portfolio_return)\n",
    "        \n",
    "        # Record portfolio state\n",
    "        portfolio_state = {\n",
    "            'date': date,\n",
    "            'capital': self.current_capital,\n",
    "            'position': self.current_position,\n",
    "            'regime': regime_info.get('most_likely_regime', -1),\n",
    "            'confidence': regime_info.get('confidence', 0),\n",
    "            'daily_return': portfolio_return,\n",
    "            'regime_probs': regime_info.get('regime_probabilities', [0, 0, 0])\n",
    "        }\n",
    "        \n",
    "        self.portfolio_history.append(portfolio_state)\n",
    "        \n",
    "        return portfolio_state\n",
    "    \n",
    "    def get_performance_summary(self):\n",
    "        \"\"\"\n",
    "        Calculate performance metrics\n",
    "        \"\"\"\n",
    "        if not self.portfolio_history:\n",
    "            return {}\n",
    "        \n",
    "        portfolio_df = pd.DataFrame(self.portfolio_history)\n",
    "        \n",
    "        total_return = (self.current_capital / self.initial_capital) - 1\n",
    "        daily_returns = portfolio_df['daily_return'].dropna()\n",
    "        \n",
    "        if len(daily_returns) > 0:\n",
    "            sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
    "            max_drawdown = self.calculate_max_drawdown(portfolio_df['capital'])\n",
    "        else:\n",
    "            sharpe_ratio = 0\n",
    "            max_drawdown = 0\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'final_capital': self.current_capital,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'total_trades': len(self.trade_history),\n",
    "            'trading_days': len(self.portfolio_history)\n",
    "        }\n",
    "    \n",
    "    def calculate_max_drawdown(self, capital_series):\n",
    "        \"\"\"\n",
    "        Calculate maximum drawdown\n",
    "        \"\"\"\n",
    "        if len(capital_series) == 0:\n",
    "            return 0\n",
    "        \n",
    "        running_max = capital_series.expanding().max()\n",
    "        drawdown = (capital_series - running_max) / running_max\n",
    "        return drawdown.min()\n",
    "\n",
    "# Initialize trading system\n",
    "trading_system = OnlineHMMTradingSystem(online_hmm, initial_capital=100000)\n",
    "\n",
    "print(f\"✅ Trading system initialized with $100,000 capital\")\n",
    "print(f\"Strategy parameters:\")\n",
    "print(f\"  Bear regime position: {trading_system.regime_positions[0]:.1%}\")\n",
    "print(f\"  Sideways regime position: {trading_system.regime_positions[1]:.1%}\")\n",
    "print(f\"  Bull regime position: {trading_system.regime_positions[2]:.1%}\")\n",
    "print(f\"  Confidence threshold: {trading_system.confidence_threshold:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trading simulation\n",
    "print(f\"\\n🔄 RUNNING TRADING SIMULATION...\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "# Use test data for trading simulation\n",
    "trading_data = test_returns[:50]  # Limit for demonstration\n",
    "trading_dates = data.index[split_point:split_point + len(trading_data)]\n",
    "trading_prices = data['Adj Close'].iloc[split_point:split_point + len(trading_data)]\n",
    "\n",
    "print(f\"Trading simulation period: {len(trading_data)} days\")\n",
    "print(f\"From {trading_dates[0].date()} to {trading_dates[-1].date()}\")\n",
    "\n",
    "# Run simulation\n",
    "simulation_start_time = time.time()\n",
    "\n",
    "for i, (date, price, return_val) in enumerate(zip(trading_dates, trading_prices, trading_data)):\n",
    "    try:\n",
    "        portfolio_state = trading_system.execute_trade(date, price, return_val)\n",
    "        \n",
    "        # Print progress every 10 days\n",
    "        if (i + 1) % 10 == 0:\n",
    "            regime = portfolio_state['regime']\n",
    "            confidence = portfolio_state['confidence']\n",
    "            capital = portfolio_state['capital']\n",
    "            position = portfolio_state['position']\n",
    "            \n",
    "            print(f\"  Day {i+1:2d} | {date.strftime('%Y-%m-%d')} | \"\n",
    "                  f\"Capital: ${capital:8,.0f} | Position: {position:6.1%} | \"\n",
    "                  f\"Regime: {regime} ({confidence:.1%})\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error on day {i+1}: {e}\")\n",
    "        break\n",
    "\n",
    "simulation_time = time.time() - simulation_start_time\n",
    "print(f\"\\n✅ Trading simulation completed in {simulation_time:.3f} seconds\")\n",
    "\n",
    "# Performance summary\n",
    "performance = trading_system.get_performance_summary()\n",
    "\n",
    "print(f\"\\n📊 TRADING PERFORMANCE SUMMARY:\")\n",
    "print(f\"=\" * 40)\n",
    "print(f\"Initial Capital: ${trading_system.initial_capital:,.0f}\")\n",
    "print(f\"Final Capital: ${performance.get('final_capital', 0):,.0f}\")\n",
    "print(f\"Total Return: {performance.get('total_return', 0):.2%}\")\n",
    "print(f\"Sharpe Ratio: {performance.get('sharpe_ratio', 0):.2f}\")\n",
    "print(f\"Max Drawdown: {performance.get('max_drawdown', 0):.2%}\")\n",
    "print(f\"Total Trades: {performance.get('total_trades', 0)}\")\n",
    "print(f\"Trading Days: {performance.get('trading_days', 0)}\")\n",
    "\n",
    "# Calculate buy-and-hold comparison\n",
    "buy_hold_return = (1 + pd.Series(trading_data)).prod() - 1\n",
    "excess_return = performance.get('total_return', 0) - buy_hold_return\n",
    "\n",
    "print(f\"\\nComparison vs Buy & Hold:\")\n",
    "print(f\"Buy & Hold Return: {buy_hold_return:.2%}\")\n",
    "print(f\"Strategy Return: {performance.get('total_return', 0):.2%}\")\n",
    "print(f\"Excess Return: {excess_return:.2%}\")\n",
    "\n",
    "if excess_return > 0:\n",
    "    print(f\"✅ Strategy outperformed buy & hold!\")\n",
    "else:\n",
    "    print(f\"⚠️ Strategy underperformed buy & hold\")\n",
    "\n",
    "# Trade analysis\n",
    "if trading_system.trade_history:\n",
    "    trades_df = pd.DataFrame(trading_system.trade_history)\n",
    "    \n",
    "    print(f\"\\n📈 TRADE ANALYSIS:\")\n",
    "    print(f\"Total position changes: {len(trades_df)}\")\n",
    "    \n",
    "    regime_trades = trades_df.groupby('regime').size()\n",
    "    print(f\"Trades by regime:\")\n",
    "    for regime, count in regime_trades.items():\n",
    "        print(f\"  Regime {regime}: {count} trades\")\n",
    "    \n",
    "    avg_confidence = trades_df['confidence'].mean()\n",
    "    print(f\"Average trading confidence: {avg_confidence:.1%}\")\n",
    "    \n",
    "    # Show recent trades\n",
    "    print(f\"\\nRecent trades:\")\n",
    "    for _, trade in trades_df.tail(5).iterrows():\n",
    "        print(f\"  {trade['date'].strftime('%Y-%m-%d')}: \"\n",
    "              f\"{trade['old_position']:6.1%} → {trade['new_position']:6.1%} \"\n",
    "              f\"(Regime {trade['regime']}, conf: {trade['confidence']:.1%})\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n⚠️ No trades executed (positions may not have changed significantly)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trading system performance\n",
    "if trading_system.portfolio_history:\n",
    "    portfolio_df = pd.DataFrame(trading_system.portfolio_history)\n",
    "    portfolio_df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Calculate buy-and-hold portfolio for comparison\n",
    "    buy_hold_capital = [trading_system.initial_capital]\n",
    "    for daily_return in trading_data:\n",
    "        buy_hold_capital.append(buy_hold_capital[-1] * (1 + daily_return))\n",
    "    \n",
    "    buy_hold_df = pd.DataFrame({\n",
    "        'capital': buy_hold_capital[1:],  # Remove initial value\n",
    "        'date': trading_dates\n",
    "    }).set_index('date')\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 16))\n",
    "    fig.suptitle('Online HMM Trading System Performance', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Portfolio value comparison\n",
    "    axes[0].plot(portfolio_df.index, portfolio_df['capital'], \n",
    "                label='HMM Strategy', linewidth=2, color='blue')\n",
    "    axes[0].plot(buy_hold_df.index, buy_hold_df['capital'], \n",
    "                label='Buy & Hold', linewidth=2, color='red', alpha=0.7)\n",
    "    \n",
    "    axes[0].set_title('Portfolio Value Comparison')\n",
    "    axes[0].set_ylabel('Capital ($)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "    \n",
    "    # Plot 2: Position sizes over time\n",
    "    axes[1].fill_between(portfolio_df.index, 0, portfolio_df['position'], \n",
    "                        where=(portfolio_df['position'] > 0), color='green', alpha=0.6, label='Long')\n",
    "    axes[1].fill_between(portfolio_df.index, 0, portfolio_df['position'], \n",
    "                        where=(portfolio_df['position'] < 0), color='red', alpha=0.6, label='Short')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    axes[1].set_title('Position Sizes Over Time')\n",
    "    axes[1].set_ylabel('Position Size')\n",
    "    axes[1].set_ylim(-1.1, 1.1)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Regime detection and confidence\n",
    "    colors = ['red', 'orange', 'green']\n",
    "    for regime in portfolio_df['regime'].unique():\n",
    "        if regime >= 0:\n",
    "            mask = portfolio_df['regime'] == regime\n",
    "            if mask.any():\n",
    "                axes[2].scatter(portfolio_df.index[mask], portfolio_df['confidence'][mask], \n",
    "                               c=colors[int(regime) % len(colors)], alpha=0.7, s=30, \n",
    "                               label=f'State {int(regime)}')\n",
    "    \n",
    "    axes[2].axhline(y=trading_system.confidence_threshold, color='black', \n",
    "                   linestyle='--', alpha=0.7, label=f'Confidence Threshold ({trading_system.confidence_threshold:.1%})')\n",
    "    axes[2].set_title('Regime Detection and Confidence')\n",
    "    axes[2].set_ylabel('Confidence')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Daily returns comparison\n",
    "    strategy_returns = portfolio_df['daily_return'].fillna(0)\n",
    "    buy_hold_returns = pd.Series(trading_data, index=trading_dates)\n",
    "    \n",
    "    axes[3].plot(strategy_returns.index, strategy_returns.cumsum(), \n",
    "                label='HMM Strategy', linewidth=2, color='blue')\n",
    "    axes[3].plot(buy_hold_returns.index, buy_hold_returns.cumsum(), \n",
    "                label='Buy & Hold', linewidth=2, color='red', alpha=0.7)\n",
    "    \n",
    "    axes[3].set_title('Cumulative Returns Comparison')\n",
    "    axes[3].set_ylabel('Cumulative Return')\n",
    "    axes[3].set_xlabel('Date')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\n📊 ADDITIONAL PERFORMANCE ANALYSIS:\")\n",
    "    print(f\"=\" * 40)\n",
    "    \n",
    "    # Volatility comparison\n",
    "    strategy_vol = strategy_returns.std() * np.sqrt(252)\n",
    "    buy_hold_vol = buy_hold_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    print(f\"Annualized Volatility:\")\n",
    "    print(f\"  HMM Strategy: {strategy_vol:.2%}\")\n",
    "    print(f\"  Buy & Hold: {buy_hold_vol:.2%}\")\n",
    "    print(f\"  Volatility Reduction: {(1 - strategy_vol/buy_hold_vol):.1%}\")\n",
    "    \n",
    "    # Risk-adjusted performance\n",
    "    strategy_sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252)\n",
    "    buy_hold_sharpe = buy_hold_returns.mean() / buy_hold_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    print(f\"\\nRisk-Adjusted Performance:\")\n",
    "    print(f\"  HMM Strategy Sharpe: {strategy_sharpe:.2f}\")\n",
    "    print(f\"  Buy & Hold Sharpe: {buy_hold_sharpe:.2f}\")\n",
    "    print(f\"  Sharpe Improvement: {strategy_sharpe - buy_hold_sharpe:.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No portfolio history to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Online HMM Features\n",
    "\n",
    "Let's explore some advanced features of Online HMMs including change point detection and model monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Online HMM features demonstration\n",
    "print(f\"🔬 ADVANCED ONLINE HMM FEATURES\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "# Feature 1: Change Point Detection\n",
    "print(f\"\\n1. CHANGE POINT DETECTION:\")\n",
    "print(f\"-\" * 25)\n",
    "\n",
    "# Monitor likelihood changes for structural breaks\n",
    "class ChangePointMonitor:\n",
    "    def __init__(self, window_size=20, threshold=0.1):\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.likelihood_history = []\n",
    "        self.change_points = []\n",
    "    \n",
    "    def add_likelihood(self, likelihood, date):\n",
    "        self.likelihood_history.append((date, likelihood))\n",
    "        \n",
    "        if len(self.likelihood_history) >= self.window_size * 2:\n",
    "            # Compare recent vs historical likelihood\n",
    "            recent_ll = np.mean([ll for _, ll in self.likelihood_history[-self.window_size:]])\n",
    "            historical_ll = np.mean([ll for _, ll in self.likelihood_history[-2*self.window_size:-self.window_size]])\n",
    "            \n",
    "            likelihood_change = abs(recent_ll - historical_ll) / abs(historical_ll)\n",
    "            \n",
    "            if likelihood_change > self.threshold:\n",
    "                self.change_points.append({\n",
    "                    'date': date,\n",
    "                    'likelihood_change': likelihood_change,\n",
    "                    'recent_ll': recent_ll,\n",
    "                    'historical_ll': historical_ll\n",
    "                })\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Initialize change point monitor\n",
    "cp_monitor = ChangePointMonitor(window_size=10, threshold=0.05)\n",
    "\n",
    "print(f\"✅ Change point monitor initialized\")\n",
    "print(f\"  Window size: {cp_monitor.window_size}\")\n",
    "print(f\"  Threshold: {cp_monitor.threshold:.1%}\")\n",
    "\n",
    "# Feature 2: Model Health Monitoring\n",
    "print(f\"\\n2. MODEL HEALTH MONITORING:\")\n",
    "print(f\"-\" * 25)\n",
    "\n",
    "class ModelHealthMonitor:\n",
    "    def __init__(self):\n",
    "        self.confidence_history = []\n",
    "        self.parameter_stability = []\n",
    "        self.processing_times = []\n",
    "        \n",
    "    def add_observation(self, confidence, processing_time, params=None):\n",
    "        self.confidence_history.append(confidence)\n",
    "        self.processing_times.append(processing_time)\n",
    "        \n",
    "        if params is not None:\n",
    "            self.parameter_stability.append(params)\n",
    "    \n",
    "    def get_health_status(self):\n",
    "        if len(self.confidence_history) < 10:\n",
    "            return {'status': 'warming_up', 'message': 'Insufficient data for health assessment'}\n",
    "        \n",
    "        # Check confidence trends\n",
    "        recent_confidence = np.mean(self.confidence_history[-10:])\n",
    "        overall_confidence = np.mean(self.confidence_history)\n",
    "        \n",
    "        # Check processing time trends\n",
    "        recent_processing = np.mean(self.processing_times[-10:])\n",
    "        avg_processing = np.mean(self.processing_times)\n",
    "        \n",
    "        health_issues = []\n",
    "        \n",
    "        if recent_confidence < 0.5:\n",
    "            health_issues.append('Low recent confidence')\n",
    "        \n",
    "        if recent_processing > avg_processing * 2:\n",
    "            health_issues.append('Processing time degradation')\n",
    "        \n",
    "        if len(self.parameter_stability) > 20:\n",
    "            # Check parameter stability (simplified)\n",
    "            param_changes = []\n",
    "            for i in range(1, min(20, len(self.parameter_stability))):\n",
    "                if isinstance(self.parameter_stability[i], dict) and isinstance(self.parameter_stability[i-1], dict):\n",
    "                    # This is a simplified check - in practice you'd compare actual parameter values\n",
    "                    param_changes.append(0.01)  # Placeholder\n",
    "            \n",
    "            if param_changes and np.mean(param_changes) > 0.05:\n",
    "                health_issues.append('High parameter instability')\n",
    "        \n",
    "        if not health_issues:\n",
    "            return {\n",
    "                'status': 'healthy', \n",
    "                'message': 'Model operating normally',\n",
    "                'confidence': recent_confidence,\n",
    "                'processing_time': recent_processing\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'status': 'warning',\n",
    "                'message': '; '.join(health_issues),\n",
    "                'confidence': recent_confidence,\n",
    "                'processing_time': recent_processing\n",
    "            }\n",
    "\n",
    "# Initialize health monitor\n",
    "health_monitor = ModelHealthMonitor()\n",
    "\n",
    "print(f\"✅ Model health monitor initialized\")\n",
    "\n",
    "# Feature 3: Adaptive Configuration\n",
    "print(f\"\\n3. ADAPTIVE CONFIGURATION:\")\n",
    "print(f\"-\" * 25)\n",
    "\n",
    "def adapt_configuration(current_config, market_volatility, confidence_trend):\n",
    "    \"\"\"\n",
    "    Adapt Online HMM configuration based on market conditions\n",
    "    \"\"\"\n",
    "    adapted_config = current_config.__dict__.copy()\n",
    "    \n",
    "    # Adapt forgetting factor based on volatility\n",
    "    if market_volatility > 0.02:  # High volatility\n",
    "        adapted_config['forgetting_factor'] = max(0.99, current_config.forgetting_factor - 0.005)\n",
    "        adapted_config['adaptation_rate'] = min(0.1, current_config.adaptation_rate + 0.01)\n",
    "    elif market_volatility < 0.01:  # Low volatility\n",
    "        adapted_config['forgetting_factor'] = min(0.999, current_config.forgetting_factor + 0.002)\n",
    "        adapted_config['adaptation_rate'] = max(0.01, current_config.adaptation_rate - 0.005)\n",
    "    \n",
    "    # Adapt based on confidence trends\n",
    "    if confidence_trend < 0.6:  # Low confidence trend\n",
    "        adapted_config['window_size'] = min(500, current_config.window_size + 50)\n",
    "    \n",
    "    return adapted_config\n",
    "\n",
    "# Demonstrate adaptive configuration\n",
    "current_vol = np.std(trading_data) if len(trading_data) > 0 else 0.015\n",
    "current_conf_trend = np.mean([p['confidence'] for p in trading_system.portfolio_history[-10:]]) if len(trading_system.portfolio_history) > 10 else 0.7\n",
    "\n",
    "adapted_config = adapt_configuration(config, current_vol, current_conf_trend)\n",
    "\n",
    "print(f\"Current market volatility: {current_vol:.4f}\")\n",
    "print(f\"Current confidence trend: {current_conf_trend:.2%}\")\n",
    "print(f\"\\nConfiguration adaptation:\")\n",
    "print(f\"  Forgetting factor: {config.forgetting_factor} → {adapted_config['forgetting_factor']}\")\n",
    "print(f\"  Adaptation rate: {config.adaptation_rate} → {adapted_config['adaptation_rate']}\")\n",
    "print(f\"  Window size: {config.window_size} → {adapted_config['window_size']}\")\n",
    "\n",
    "# Feature 4: Performance Monitoring\n",
    "print(f\"\\n4. PERFORMANCE MONITORING:\")\n",
    "print(f\"-\" * 25)\n",
    "\n",
    "# Simulate monitoring on recent data\n",
    "monitoring_data = test_returns[-20:] if len(test_returns) >= 20 else test_returns\n",
    "monitoring_dates = data.index[split_point + len(test_returns) - len(monitoring_data):split_point + len(test_returns)]\n",
    "\n",
    "print(f\"Monitoring last {len(monitoring_data)} observations...\")\n",
    "\n",
    "for i, (date, return_val) in enumerate(zip(monitoring_dates, monitoring_data)):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Update model (if needed)\n",
    "        online_hmm.update(return_val)\n",
    "        regime_info = online_hmm.get_current_regime_info()\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Update monitors\n",
    "        confidence = regime_info.get('confidence', 0)\n",
    "        health_monitor.add_observation(confidence, processing_time)\n",
    "        \n",
    "        # Check for change points (simplified - using dummy likelihood)\n",
    "        dummy_likelihood = -abs(return_val) * 100  # Simplified likelihood proxy\n",
    "        change_detected = cp_monitor.add_likelihood(dummy_likelihood, date)\n",
    "        \n",
    "        if change_detected:\n",
    "            print(f\"  ⚠️ Change point detected on {date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            health_status = health_monitor.get_health_status()\n",
    "            print(f\"  Health check {i+1}: {health_status['status']} - {health_status['message']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Monitoring error on {date}: {e}\")\n",
    "\n",
    "# Final health assessment\n",
    "final_health = health_monitor.get_health_status()\n",
    "print(f\"\\n📊 FINAL MODEL HEALTH ASSESSMENT:\")\n",
    "print(f\"Status: {final_health['status']}\")\n",
    "print(f\"Message: {final_health['message']}\")\n",
    "if 'confidence' in final_health:\n",
    "    print(f\"Recent confidence: {final_health['confidence']:.1%}\")\n",
    "if 'processing_time' in final_health:\n",
    "    print(f\"Avg processing time: {final_health['processing_time']*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nChange points detected: {len(cp_monitor.change_points)}\")\n",
    "for cp in cp_monitor.change_points[-3:]:  # Show last 3\n",
    "    print(f\"  {cp['date'].strftime('%Y-%m-%d')}: {cp['likelihood_change']:.1%} change\")\n",
    "\n",
    "print(f\"\\n✅ Advanced features demonstration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices\n",
    "\n",
    "In this tutorial, we've explored the power of Online Hidden Markov Models for real-time financial regime detection. Let's summarize the key concepts and best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Online HMM capabilities and recommendations\n",
    "print(f\"📋 ONLINE HMM TUTORIAL SUMMARY\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "print(f\"\\n✅ WHAT WE ACCOMPLISHED:\")\n",
    "print(f\"1. Configured and initialized Online HMM for streaming data\")\n",
    "print(f\"2. Processed real-time market data with sub-millisecond latency\")\n",
    "print(f\"3. Analyzed parameter evolution and model adaptation\")\n",
    "print(f\"4. Compared Online vs Batch HMM performance\")\n",
    "print(f\"5. Built a complete real-time trading system\")\n",
    "print(f\"6. Demonstrated advanced monitoring and health checks\")\n",
    "print(f\"7. Explored adaptive configuration strategies\")\n",
    "\n",
    "print(f\"\\n🎯 KEY ADVANTAGES OF ONLINE HMM:\")\n",
    "print(f\"• Real-time Processing: O(1) complexity per observation\")\n",
    "print(f\"• Memory Efficiency: Fixed memory usage regardless of data size\")\n",
    "print(f\"• Adaptive Learning: Parameters evolve with market conditions\")\n",
    "print(f\"• Temporal Consistency: Stable historical regime classifications\")\n",
    "print(f\"• Low Latency: Suitable for high-frequency trading applications\")\n",
    "print(f\"• Robust to Non-stationarity: Handles changing market dynamics\")\n",
    "\n",
    "print(f\"\\n⚙️ CONFIGURATION BEST PRACTICES:\")\n",
    "print(f\"\\nForgetting Factor (0.99-0.999):\")\n",
    "print(f\"  • Higher values (0.999): Stable markets, long-term trends\")\n",
    "print(f\"  • Lower values (0.99): Volatile markets, quick adaptation\")\n",
    "print(f\"  • Adaptive: Adjust based on market volatility\")\n",
    "\n",
    "print(f\"\\nAdaptation Rate (0.01-0.1):\")\n",
    "print(f\"  • Higher values (0.1): Fast adaptation, less stability\")\n",
    "print(f\"  • Lower values (0.01): Slow adaptation, more stability\")\n",
    "print(f\"  • Recommended: 0.05 for balanced performance\")\n",
    "\n",
    "print(f\"\\nWindow Size (100-500):\")\n",
    "print(f\"  • Larger windows: More stable, slower adaptation\")\n",
    "print(f\"  • Smaller windows: Less stable, faster adaptation\")\n",
    "print(f\"  • Recommended: 252 (1 trading year) for daily data\")\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE GUIDELINES:\")\n",
    "print(f\"\\nExpected Processing Times:\")\n",
    "print(f\"  • Excellent: <1ms per observation\")\n",
    "print(f\"  • Good: 1-10ms per observation\")\n",
    "print(f\"  • Needs optimization: >10ms per observation\")\n",
    "\n",
    "print(f\"\\nConfidence Thresholds:\")\n",
    "print(f\"  • High confidence: >80% (strong regime signal)\")\n",
    "print(f\"  • Medium confidence: 60-80% (moderate regime signal)\")\n",
    "print(f\"  • Low confidence: <60% (uncertain regime)\")\n",
    "\n",
    "print(f\"\\n🚨 COMMON PITFALLS AND SOLUTIONS:\")\n",
    "print(f\"\\n1. Parameter Instability:\")\n",
    "print(f\"   Problem: Parameters change too rapidly\")\n",
    "print(f\"   Solution: Increase forgetting factor, decrease adaptation rate\")\n",
    "\n",
    "print(f\"\\n2. Slow Adaptation:\")\n",
    "print(f\"   Problem: Model doesn't adapt to regime changes\")\n",
    "print(f\"   Solution: Decrease forgetting factor, increase adaptation rate\")\n",
    "\n",
    "print(f\"\\n3. Low Confidence:\")\n",
    "print(f\"   Problem: Model is uncertain about regime classifications\")\n",
    "print(f\"   Solution: Increase window size, add more features, check data quality\")\n",
    "\n",
    "print(f\"\\n4. Memory Issues:\")\n",
    "print(f\"   Problem: Model uses too much memory\")\n",
    "   f\"   Solution: Reduce window size, implement proper cleanup\")\n",
    "\n",
    "print(f\"\\n🔧 PRODUCTION DEPLOYMENT CHECKLIST:\")\n",
    "print(f\"□ Configure appropriate forgetting factor for market conditions\")\n",
    "print(f\"□ Set up model health monitoring and alerting\")\n",
    "print(f\"□ Implement change point detection for structural breaks\")\n",
    "print(f\"□ Add proper error handling and recovery mechanisms\")\n",
    "print(f\"□ Set up parameter logging and visualization\")\n",
    "print(f\"□ Implement adaptive configuration based on market conditions\")\n",
    "print(f\"□ Add transaction cost modeling and position size limits\")\n",
    "print(f\"□ Set up backtesting and performance validation\")\n",
    "print(f\"□ Implement proper risk management and stop-loss mechanisms\")\n",
    "print(f\"□ Add model versioning and rollback capabilities\")\n",
    "\n",
    "print(f\"\\n📈 NEXT STEPS:\")\n",
    "print(f\"1. Explore multivariate Online HMMs with additional features\")\n",
    "print(f\"2. Implement portfolio-level regime detection across assets\")\n",
    "print(f\"3. Add more sophisticated trading strategies and risk management\")\n",
    "print(f\"4. Integrate with live market data feeds\")\n",
    "print(f\"5. Develop automated parameter optimization\")\n",
    "print(f\"6. Build comprehensive backtesting and validation frameworks\")\n",
    "\n",
    "print(f\"\\n⚠️ IMPORTANT DISCLAIMERS:\")\n",
    "print(f\"• Past performance does not guarantee future results\")\n",
    "print(f\"• This is educational content, not financial advice\")\n",
    "print(f\"• Always implement proper risk management in production\")\n",
    "print(f\"• Consider transaction costs and market impact in real trading\")\n",
    "print(f\"• Validate models extensively before deployment\")\n",
    "\n",
    "print(f\"\\n🎉 CONGRATULATIONS!\")\n",
    "print(f\"You've successfully mastered Online Hidden Markov Models for\")\n",
    "print(f\"real-time financial regime detection and trading applications!\")\n",
    "print(f\"\\nHappy trading! 🚀📈\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}