{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Hidden Markov Models for Financial Markets\n",
    "\n",
    "This notebook provides an interactive introduction to using Hidden Markov Models (HMMs) for detecting market regimes in financial time series data.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will understand:\n",
    "1. The basic concepts of market regimes\n",
    "2. How HMMs model regime-switching behavior\n",
    "3. How to implement and train an HMM on financial data\n",
    "4. How to interpret regime classifications and transitions\n",
    "5. Practical applications for trading strategies\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of probability and statistics\n",
    "- Familiarity with Python and NumPy\n",
    "- Knowledge of financial time series concepts (returns, volatility)\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our HMM models\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from hidden_regime.models.base_hmm import HiddenMarkovModel\n",
    "from hidden_regime.models.online_hmm import OnlineHMM, OnlineHMMConfig\n",
    "from hidden_regime.data.loader import DataLoader\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Market Regimes\n",
    "\n",
    "Financial markets don't behave uniformly over time. Instead, they exhibit different **regimes** characterized by distinct statistical properties:\n",
    "\n",
    "- **Bull Markets**: Positive mean returns, moderate volatility, sustained upward trends\n",
    "- **Bear Markets**: Negative mean returns, high volatility, sustained downward trends  \n",
    "- **Sideways Markets**: Returns around zero, low volatility, range-bound trading\n",
    "- **Crisis Markets**: Very negative returns, extreme volatility, rapid changes\n",
    "\n",
    "Let's start by loading some real market data to visualize these regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download market data for SPY (S&P 500 ETF)\n",
    "ticker = \"SPY\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "print(f\"Downloading {ticker} data from {start_date} to {end_date}...\")\n",
    "spy_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "# Calculate log returns\n",
    "spy_data['Log_Return'] = np.log(spy_data['Adj Close'] / spy_data['Adj Close'].shift(1))\n",
    "spy_data = spy_data.dropna()\n",
    "\n",
    "print(f\"‚úÖ Downloaded {len(spy_data)} days of data\")\n",
    "print(f\"Date range: {spy_data.index[0].date()} to {spy_data.index[-1].date()}\")\n",
    "\n",
    "# Display basic statistics\n",
    "returns = spy_data['Log_Return']\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"Mean daily return: {returns.mean():.4f} ({returns.mean()*252:.2%} annualized)\")\n",
    "print(f\"Daily volatility: {returns.std():.4f} ({returns.std()*np.sqrt(252):.2%} annualized)\")\n",
    "print(f\"Minimum return: {returns.min():.4f}\")\n",
    "print(f\"Maximum return: {returns.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Price chart\n",
    "axes[0].plot(spy_data.index, spy_data['Adj Close'], linewidth=1.5, color='darkblue')\n",
    "axes[0].set_title(f'{ticker} Adjusted Close Price', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight major market events\n",
    "covid_crash = pd.Timestamp('2020-03-15')\n",
    "if covid_crash in spy_data.index:\n",
    "    axes[0].axvline(covid_crash, color='red', linestyle='--', alpha=0.7, label='COVID-19 Crash')\n",
    "    axes[0].legend()\n",
    "\n",
    "# Plot 2: Daily returns\n",
    "axes[1].plot(spy_data.index, returns, linewidth=0.8, color='darkgreen', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[1].set_title('Daily Log Returns', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Log Return')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Rolling volatility\n",
    "rolling_vol = returns.rolling(window=20).std() * np.sqrt(252)  # 20-day annualized volatility\n",
    "axes[2].plot(spy_data.index, rolling_vol, linewidth=1.5, color='darkorange')\n",
    "axes[2].set_title('20-Day Rolling Volatility (Annualized)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Volatility')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Notice how different periods show distinct characteristics:\")\n",
    "print(\"‚Ä¢ Early 2020: Low volatility, steady uptrend (Bull regime)\")\n",
    "print(\"‚Ä¢ March 2020: Extreme volatility, large negative returns (Crisis regime)\")\n",
    "print(\"‚Ä¢ Mid 2020-2021: Recovery with moderate volatility (Bull regime)\")\n",
    "print(\"‚Ä¢ 2022-2023: Mixed periods with varying volatility (Mixed regimes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Hidden Markov Models\n",
    "\n",
    "A Hidden Markov Model is perfect for modeling market regimes because:\n",
    "\n",
    "1. **Hidden States**: The actual regime (Bull/Bear/Sideways) is not directly observable\n",
    "2. **Observable Emissions**: We observe returns that are generated by the hidden regime\n",
    "3. **Markov Property**: Regimes change according to a probabilistic transition model\n",
    "4. **Regime Persistence**: Each regime has a tendency to persist for multiple periods\n",
    "\n",
    "### HMM Components\n",
    "\n",
    "- **States (S)**: The hidden regimes {Bull, Bear, Sideways}\n",
    "- **Observations (O)**: The observed returns {r‚ÇÅ, r‚ÇÇ, ..., r‚Çú}\n",
    "- **Transition Matrix (A)**: P(state_t+1 | state_t)\n",
    "- **Emission Parameters (B)**: P(return_t | state_t) ~ N(Œº‚Çõ, œÉ‚Çõ¬≤)\n",
    "- **Initial Distribution (œÄ)**: P(state_1)\n",
    "\n",
    "Let's build our first HMM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a 3-state HMM\n",
    "print(\"üîÑ Training Hidden Markov Model with 3 states...\")\n",
    "print(\"This may take a few moments...\")\n",
    "\n",
    "# Prepare the data\n",
    "returns_array = returns.values.reshape(-1, 1)  # HMM expects 2D array\n",
    "\n",
    "# Create and train the model\n",
    "hmm = HiddenMarkovModel(n_states=3, random_state=42)\n",
    "hmm.fit(returns_array)\n",
    "\n",
    "# Check if training was successful\n",
    "if hasattr(hmm, 'training_history_') and 'final_log_likelihood' in hmm.training_history_:\n",
    "    final_ll = hmm.training_history_['final_log_likelihood']\n",
    "    print(f\"‚úÖ Model trained successfully!\")\n",
    "    print(f\"Final log-likelihood: {final_ll:.2f}\")\n",
    "    print(f\"Converged after {len(hmm.training_history_['log_likelihoods'])} iterations\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training completed but convergence information not available\")\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"Number of states: {hmm.n_states}\")\n",
    "print(f\"Number of features: {hmm.n_features}\")\n",
    "print(f\"Model type: {type(hmm).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and interpret the model parameters\n",
    "transition_matrix = hmm.transition_matrix_\n",
    "means = hmm.emission_means_\n",
    "covariances = hmm.emission_covariances_\n",
    "\n",
    "print(\"üéØ Model Parameters Interpretation:\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REGIME CHARACTERISTICS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Sort regimes by mean return for easier interpretation\n",
    "regime_order = np.argsort(means.flatten())\n",
    "regime_names = ['Bear üêª', 'Sideways ‚ÜîÔ∏è', 'Bull üêÇ']\n",
    "\n",
    "for i, regime_idx in enumerate(regime_order):\n",
    "    mean_return = means[regime_idx, 0]\n",
    "    volatility = np.sqrt(covariances[regime_idx, 0, 0])\n",
    "    \n",
    "    print(f\"\\n{regime_names[i]} (State {regime_idx}):\")\n",
    "    print(f\"  Mean daily return: {mean_return:.4f} ({mean_return*252:.1%} annualized)\")\n",
    "    print(f\"  Daily volatility:  {volatility:.4f} ({volatility*np.sqrt(252):.1%} annualized)\")\n",
    "    \n",
    "    # Calculate average duration in this state\n",
    "    persistence_prob = transition_matrix[regime_idx, regime_idx]\n",
    "    avg_duration = 1 / (1 - persistence_prob) if persistence_prob < 1 else float('inf')\n",
    "    print(f\"  Persistence prob:  {persistence_prob:.3f}\")\n",
    "    print(f\"  Average duration:  {avg_duration:.1f} days\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRANSITION MATRIX (probability of switching):\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nFrom \\\\ To    Bear     Sideways    Bull\")\n",
    "for i, from_regime in enumerate(regime_names):\n",
    "    row = [transition_matrix[regime_order[i], regime_order[j]] for j in range(3)]\n",
    "    print(f\"{from_regime:<10} {row[0]:.3f}    {row[1]:.3f}     {row[2]:.3f}\")\n",
    "\n",
    "# Calculate stationary distribution\n",
    "eigenvals, eigenvecs = np.linalg.eig(transition_matrix.T)\n",
    "stationary = eigenvecs[:, np.argmax(eigenvals)].real\n",
    "stationary = stationary / stationary.sum()\n",
    "\n",
    "print(f\"\\nüìä Long-term regime probabilities:\")\n",
    "for i, regime_idx in enumerate(regime_order):\n",
    "    print(f\"  {regime_names[i]}: {stationary[regime_idx]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regime Detection and Analysis\n",
    "\n",
    "Now let's use our trained model to detect regimes in our historical data. The model can provide:\n",
    "\n",
    "1. **Most Likely State Sequence**: Using the Viterbi algorithm\n",
    "2. **State Probabilities**: Using the Forward-Backward algorithm\n",
    "3. **Regime Confidence**: How certain the model is about each classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the most likely state sequence (Viterbi algorithm)\n",
    "print(\"üîç Detecting market regimes using Viterbi algorithm...\")\n",
    "state_sequence = hmm.predict(returns_array)\n",
    "\n",
    "# Calculate state probabilities (Forward-Backward algorithm)  \n",
    "print(\"üìä Calculating regime probabilities using Forward-Backward algorithm...\")\n",
    "state_probs = hmm.predict_proba(returns_array)\n",
    "\n",
    "# Add results to our dataframe\n",
    "spy_data['Regime'] = state_sequence\n",
    "spy_data['Bear_Prob'] = state_probs[:, regime_order[0]]\n",
    "spy_data['Sideways_Prob'] = state_probs[:, regime_order[1]]\n",
    "spy_data['Bull_Prob'] = state_probs[:, regime_order[2]]\n",
    "\n",
    "# Map numerical states to regime names for plotting\n",
    "regime_mapping = {regime_order[i]: regime_names[i] for i in range(3)}\n",
    "spy_data['Regime_Name'] = spy_data['Regime'].map(regime_mapping)\n",
    "\n",
    "print(f\"‚úÖ Regime detection complete!\")\n",
    "print(f\"\\nRegime Distribution:\")\n",
    "regime_counts = spy_data['Regime_Name'].value_counts()\n",
    "for regime, count in regime_counts.items():\n",
    "    percentage = (count / len(spy_data)) * 100\n",
    "    print(f\"  {regime}: {count} days ({percentage:.1f}%)\")\n",
    "\n",
    "# Calculate confidence statistics\n",
    "max_probs = state_probs.max(axis=1)\n",
    "print(f\"\\nClassification Confidence:\")\n",
    "print(f\"  Average confidence: {max_probs.mean():.1%}\")\n",
    "print(f\"  High confidence days (>80%): {(max_probs > 0.8).sum()} ({(max_probs > 0.8).mean():.1%})\")\n",
    "print(f\"  Low confidence days (<60%): {(max_probs < 0.6).sum()} ({(max_probs < 0.6).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regime detection results\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 16))\n",
    "\n",
    "# Define colors for regimes\n",
    "regime_colors = {regime_order[0]: 'red', regime_order[1]: 'orange', regime_order[2]: 'green'}\n",
    "\n",
    "# Plot 1: Price with regime coloring\n",
    "for regime_idx, color in regime_colors.items():\n",
    "    mask = spy_data['Regime'] == regime_idx\n",
    "    if mask.any():\n",
    "        regime_name = regime_mapping[regime_idx]\n",
    "        axes[0].scatter(spy_data.index[mask], spy_data['Adj Close'][mask], \n",
    "                       c=color, alpha=0.6, s=8, label=regime_name)\n",
    "\n",
    "axes[0].plot(spy_data.index, spy_data['Adj Close'], 'k-', alpha=0.3, linewidth=0.5)\n",
    "axes[0].set_title('Stock Price Colored by Detected Regime', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Returns with regime coloring\n",
    "for regime_idx, color in regime_colors.items():\n",
    "    mask = spy_data['Regime'] == regime_idx\n",
    "    if mask.any():\n",
    "        axes[1].scatter(spy_data.index[mask], spy_data['Log_Return'][mask], \n",
    "                       c=color, alpha=0.6, s=8)\n",
    "\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[1].set_title('Daily Returns Colored by Detected Regime', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Log Return')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Regime probabilities as stacked area\n",
    "axes[2].fill_between(spy_data.index, 0, spy_data['Bear_Prob'], \n",
    "                    color='red', alpha=0.7, label='Bear üêª')\n",
    "axes[2].fill_between(spy_data.index, spy_data['Bear_Prob'], \n",
    "                    spy_data['Bear_Prob'] + spy_data['Sideways_Prob'], \n",
    "                    color='orange', alpha=0.7, label='Sideways ‚ÜîÔ∏è')\n",
    "axes[2].fill_between(spy_data.index, spy_data['Bear_Prob'] + spy_data['Sideways_Prob'], 1,\n",
    "                    color='green', alpha=0.7, label='Bull üêÇ')\n",
    "\n",
    "axes[2].set_title('Regime Probabilities Over Time', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Probability')\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].legend(loc='upper right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Classification confidence\n",
    "confidence = state_probs.max(axis=1)\n",
    "axes[3].plot(spy_data.index, confidence, 'navy', linewidth=1, alpha=0.8)\n",
    "axes[3].axhline(y=0.8, color='green', linestyle='--', alpha=0.7, label='High Confidence (80%)')\n",
    "axes[3].axhline(y=0.6, color='orange', linestyle='--', alpha=0.7, label='Low Confidence (60%)')\n",
    "axes[3].fill_between(spy_data.index, 0.8, 1, alpha=0.2, color='green')\n",
    "axes[3].fill_between(spy_data.index, 0, 0.6, alpha=0.2, color='red')\n",
    "\n",
    "axes[3].set_title('Classification Confidence Over Time', fontsize=14, fontweight='bold')\n",
    "axes[3].set_ylabel('Confidence')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].set_ylim(0, 1)\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Observations:\")\n",
    "print(\"‚Ä¢ Red periods (Bear): Correspond to market downturns and high volatility\")\n",
    "print(\"‚Ä¢ Green periods (Bull): Align with strong upward trends\")\n",
    "print(\"‚Ä¢ Orange periods (Sideways): Show during consolidation phases\")\n",
    "print(\"‚Ä¢ Lower confidence often occurs during regime transitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regime Analysis and Statistics\n",
    "\n",
    "Let's dive deeper into the characteristics of each detected regime and analyze how well our model captures market behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze regime characteristics\n",
    "print(\"üìà DETAILED REGIME ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "regime_stats = []\n",
    "\n",
    "for i, regime_idx in enumerate(regime_order):\n",
    "    regime_data = spy_data[spy_data['Regime'] == regime_idx]\n",
    "    returns_regime = regime_data['Log_Return']\n",
    "    \n",
    "    if len(returns_regime) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'regime_name': regime_names[i],\n",
    "        'regime_idx': regime_idx,\n",
    "        'n_days': len(returns_regime),\n",
    "        'percentage': len(returns_regime) / len(spy_data) * 100,\n",
    "        'mean_return': returns_regime.mean(),\n",
    "        'volatility': returns_regime.std(),\n",
    "        'sharpe_ratio': returns_regime.mean() / returns_regime.std() * np.sqrt(252) if returns_regime.std() > 0 else 0,\n",
    "        'min_return': returns_regime.min(),\n",
    "        'max_return': returns_regime.max(),\n",
    "        'positive_days': (returns_regime > 0).sum(),\n",
    "        'negative_days': (returns_regime < 0).sum(),\n",
    "        'win_rate': (returns_regime > 0).mean(),\n",
    "        'avg_positive': returns_regime[returns_regime > 0].mean() if (returns_regime > 0).any() else 0,\n",
    "        'avg_negative': returns_regime[returns_regime < 0].mean() if (returns_regime < 0).any() else 0\n",
    "    }\n",
    "    \n",
    "    regime_stats.append(stats)\n",
    "    \n",
    "    print(f\"\\n{regime_names[i]} REGIME (State {regime_idx}):\")\n",
    "    print(f\"  Duration: {stats['n_days']} days ({stats['percentage']:.1f}% of time)\")\n",
    "    print(f\"  Mean daily return: {stats['mean_return']:.4f} ({stats['mean_return']*252:.1%} annualized)\")\n",
    "    print(f\"  Daily volatility: {stats['volatility']:.4f} ({stats['volatility']*np.sqrt(252):.1%} annualized)\")\n",
    "    print(f\"  Sharpe ratio: {stats['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  Win rate: {stats['win_rate']:.1%}\")\n",
    "    print(f\"  Best day: {stats['max_return']:.3f}\")\n",
    "    print(f\"  Worst day: {stats['min_return']:.3f}\")\n",
    "    print(f\"  Avg positive day: {stats['avg_positive']:.4f}\")\n",
    "    print(f\"  Avg negative day: {stats['avg_negative']:.4f}\")\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "regime_df = pd.DataFrame(regime_stats)\n",
    "print(f\"\\nüìä REGIME COMPARISON TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "comparison_cols = ['regime_name', 'n_days', 'mean_return', 'volatility', 'sharpe_ratio', 'win_rate']\n",
    "display_df = regime_df[comparison_cols].copy()\n",
    "display_df['mean_return'] = display_df['mean_return'].apply(lambda x: f\"{x:.4f}\")\n",
    "display_df['volatility'] = display_df['volatility'].apply(lambda x: f\"{x:.4f}\")\n",
    "display_df['sharpe_ratio'] = display_df['sharpe_ratio'].apply(lambda x: f\"{x:.2f}\")\n",
    "display_df['win_rate'] = display_df['win_rate'].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime characteristics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Regime Characteristics Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Colors for regimes\n",
    "colors = ['red', 'orange', 'green']\n",
    "\n",
    "# Plot 1: Return distributions by regime\n",
    "for i, regime_idx in enumerate(regime_order):\n",
    "    regime_returns = spy_data[spy_data['Regime'] == regime_idx]['Log_Return']\n",
    "    if len(regime_returns) > 0:\n",
    "        axes[0, 0].hist(regime_returns, bins=30, alpha=0.6, color=colors[i], \n",
    "                       label=regime_names[i], density=True)\n",
    "\n",
    "axes[0, 0].set_title('Return Distribution by Regime')\n",
    "axes[0, 0].set_xlabel('Daily Return')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].axvline(0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Risk-Return scatter\n",
    "for i, stats in enumerate(regime_stats):\n",
    "    axes[0, 1].scatter(stats['volatility'] * np.sqrt(252), \n",
    "                      stats['mean_return'] * 252, \n",
    "                      s=stats['n_days']*2, alpha=0.7, color=colors[i],\n",
    "                      label=stats['regime_name'])\n",
    "\n",
    "axes[0, 1].set_title('Risk-Return Profile by Regime\\n(bubble size = duration)')\n",
    "axes[0, 1].set_xlabel('Annualized Volatility')\n",
    "axes[0, 1].set_ylabel('Annualized Return')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].axvline(0.15, color='gray', linestyle=':', alpha=0.5, label='15% vol')\n",
    "\n",
    "# Plot 3: Win rates\n",
    "win_rates = [stats['win_rate'] for stats in regime_stats]\n",
    "regime_labels = [stats['regime_name'] for stats in regime_stats]\n",
    "bars = axes[0, 2].bar(regime_labels, win_rates, color=colors[:len(regime_stats)], alpha=0.7)\n",
    "axes[0, 2].set_title('Win Rate by Regime')\n",
    "axes[0, 2].set_ylabel('Probability of Positive Return')\n",
    "axes[0, 2].set_ylim(0, 1)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "axes[0, 2].axhline(0.5, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, rate in zip(bars, win_rates):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{rate:.1%}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Regime duration analysis\n",
    "regime_durations = []\n",
    "regime_labels_duration = []\n",
    "\n",
    "# Calculate regime run lengths\n",
    "current_regime = spy_data['Regime'].iloc[0]\n",
    "current_duration = 1\n",
    "\n",
    "for i in range(1, len(spy_data)):\n",
    "    if spy_data['Regime'].iloc[i] == current_regime:\n",
    "        current_duration += 1\n",
    "    else:\n",
    "        regime_durations.append(current_duration)\n",
    "        regime_labels_duration.append(regime_mapping[current_regime])\n",
    "        current_regime = spy_data['Regime'].iloc[i]\n",
    "        current_duration = 1\n",
    "\n",
    "# Add the last regime\n",
    "regime_durations.append(current_duration)\n",
    "regime_labels_duration.append(regime_mapping[current_regime])\n",
    "\n",
    "# Box plot of durations\n",
    "duration_data = []\n",
    "duration_labels = []\n",
    "for regime_name in regime_names:\n",
    "    regime_dur = [dur for dur, label in zip(regime_durations, regime_labels_duration) \n",
    "                  if label == regime_name]\n",
    "    if regime_dur:\n",
    "        duration_data.append(regime_dur)\n",
    "        duration_labels.append(regime_name)\n",
    "\n",
    "if duration_data:\n",
    "    bp = axes[1, 0].boxplot(duration_data, labels=duration_labels, patch_artist=True)\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(duration_data)]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "axes[1, 0].set_title('Regime Duration Distribution')\n",
    "axes[1, 0].set_ylabel('Duration (days)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Monthly regime frequency\n",
    "spy_data['Month'] = spy_data.index.to_period('M')\n",
    "monthly_regimes = spy_data.groupby(['Month', 'Regime_Name']).size().unstack(fill_value=0)\n",
    "monthly_regimes_pct = monthly_regimes.div(monthly_regimes.sum(axis=1), axis=0)\n",
    "\n",
    "if not monthly_regimes_pct.empty:\n",
    "    monthly_regimes_pct.plot(kind='area', stacked=True, ax=axes[1, 1], \n",
    "                            color=['red', 'green', 'orange'], alpha=0.7)\n",
    "    axes[1, 1].set_title('Regime Composition Over Time (Monthly)')\n",
    "    axes[1, 1].set_ylabel('Regime Percentage')\n",
    "    axes[1, 1].set_xlabel('Month')\n",
    "    axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Transition frequency\n",
    "transition_counts = np.zeros((3, 3))\n",
    "for i in range(len(spy_data) - 1):\n",
    "    current_state = spy_data['Regime'].iloc[i]\n",
    "    next_state = spy_data['Regime'].iloc[i + 1]\n",
    "    \n",
    "    current_idx = list(regime_order).index(current_state)\n",
    "    next_idx = list(regime_order).index(next_state)\n",
    "    \n",
    "    transition_counts[current_idx, next_idx] += 1\n",
    "\n",
    "# Normalize to get transition probabilities\n",
    "transition_probs = transition_counts / transition_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "im = axes[1, 2].imshow(transition_probs, cmap='YlOrRd', vmin=0, vmax=1)\n",
    "axes[1, 2].set_title('Observed Transition Matrix')\n",
    "axes[1, 2].set_xticks(range(3))\n",
    "axes[1, 2].set_yticks(range(3))\n",
    "axes[1, 2].set_xticklabels(regime_names)\n",
    "axes[1, 2].set_yticklabels(regime_names)\n",
    "axes[1, 2].set_xlabel('To Regime')\n",
    "axes[1, 2].set_ylabel('From Regime')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = axes[1, 2].text(j, i, f'{transition_probs[i, j]:.2f}',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "plt.colorbar(im, ax=axes[1, 2])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trading Applications\n",
    "\n",
    "Now let's explore how to use regime detection for practical trading strategies. We'll implement a simple regime-based trading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a regime-based trading strategy\n",
    "print(\"üí∞ REGIME-BASED TRADING STRATEGY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define trading rules based on regimes\n",
    "def get_position_size(regime_name, confidence, base_size=1.0):\n",
    "    \"\"\"\n",
    "    Determine position size based on regime and confidence\n",
    "    \n",
    "    Args:\n",
    "        regime_name: Current regime ('Bear üêª', 'Sideways ‚ÜîÔ∏è', 'Bull üêÇ')\n",
    "        confidence: Confidence in regime classification (0-1)\n",
    "        base_size: Base position size\n",
    "    \n",
    "    Returns:\n",
    "        Position size (-1 to 1, where negative means short)\n",
    "    \"\"\"\n",
    "    # Base position by regime\n",
    "    regime_positions = {\n",
    "        'Bear üêª': -0.5,    # Short position in bear markets\n",
    "        'Sideways ‚ÜîÔ∏è': 0.0,  # Neutral in sideways markets\n",
    "        'Bull üêÇ': 1.0       # Long position in bull markets\n",
    "    }\n",
    "    \n",
    "    base_position = regime_positions.get(regime_name, 0.0)\n",
    "    \n",
    "    # Scale by confidence (minimum 20% position when uncertain)\n",
    "    confidence_scaling = max(0.2, confidence)\n",
    "    \n",
    "    return base_position * confidence_scaling * base_size\n",
    "\n",
    "# Calculate positions for each day\n",
    "spy_data['Position'] = spy_data.apply(\n",
    "    lambda row: get_position_size(\n",
    "        row['Regime_Name'], \n",
    "        max(row['Bear_Prob'], row['Sideways_Prob'], row['Bull_Prob'])\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate strategy returns (assuming we can trade at close prices)\n",
    "# Position is determined at close and executed next day\n",
    "spy_data['Strategy_Return'] = spy_data['Position'].shift(1) * spy_data['Log_Return']\n",
    "spy_data['Strategy_Return'] = spy_data['Strategy_Return'].fillna(0)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "spy_data['Buy_Hold_Cumulative'] = (1 + spy_data['Log_Return']).cumprod()\n",
    "spy_data['Strategy_Cumulative'] = (1 + spy_data['Strategy_Return']).cumprod()\n",
    "\n",
    "# Performance metrics\n",
    "def calculate_performance_metrics(returns, name=\"Strategy\"):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    returns = returns.dropna()\n",
    "    \n",
    "    if len(returns) == 0 or returns.std() == 0:\n",
    "        return {f'{name} Total Return': 0, f'{name} Sharpe Ratio': 0, f'{name} Max Drawdown': 0}\n",
    "    \n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    annualized_return = (1 + returns).prod() ** (252 / len(returns)) - 1\n",
    "    annualized_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annualized_return - 0.02) / annualized_vol  # Assume 2% risk-free rate\n",
    "    \n",
    "    # Calculate maximum drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Calculate other metrics\n",
    "    positive_days = (returns > 0).sum()\n",
    "    total_days = len(returns)\n",
    "    win_rate = positive_days / total_days if total_days > 0 else 0\n",
    "    \n",
    "    # Downside deviation (for Sortino ratio)\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0.001\n",
    "    sortino_ratio = (annualized_return - 0.02) / downside_vol if downside_vol > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        f'{name} Total Return': total_return,\n",
    "        f'{name} Annualized Return': annualized_return,\n",
    "        f'{name} Annualized Volatility': annualized_vol,\n",
    "        f'{name} Sharpe Ratio': sharpe_ratio,\n",
    "        f'{name} Sortino Ratio': sortino_ratio,\n",
    "        f'{name} Max Drawdown': max_drawdown,\n",
    "        f'{name} Win Rate': win_rate\n",
    "    }\n",
    "\n",
    "# Calculate performance for both strategies\n",
    "buy_hold_metrics = calculate_performance_metrics(spy_data['Log_Return'], 'Buy & Hold')\n",
    "strategy_metrics = calculate_performance_metrics(spy_data['Strategy_Return'], 'HMM Strategy')\n",
    "\n",
    "# Combine metrics\n",
    "all_metrics = {**buy_hold_metrics, **strategy_metrics}\n",
    "\n",
    "print(\"üìä PERFORMANCE COMPARISON:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Metric':<25} {'Buy & Hold':<15} {'HMM Strategy':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "metrics_to_show = [\n",
    "    ('Total Return', '%'),\n",
    "    ('Annualized Return', '%'),\n",
    "    ('Annualized Volatility', '%'),\n",
    "    ('Sharpe Ratio', '.2f'),\n",
    "    ('Sortino Ratio', '.2f'),\n",
    "    ('Max Drawdown', '%'),\n",
    "    ('Win Rate', '%')\n",
    "]\n",
    "\n",
    "for metric, fmt in metrics_to_show:\n",
    "    bh_val = all_metrics.get(f'Buy & Hold {metric}', 0)\n",
    "    str_val = all_metrics.get(f'HMM Strategy {metric}', 0)\n",
    "    \n",
    "    if fmt == '%':\n",
    "        bh_str = f\"{bh_val:.1%}\"\n",
    "        str_str = f\"{str_val:.1%}\"\n",
    "    else:\n",
    "        bh_str = f\"{bh_val:.2f}\"\n",
    "        str_str = f\"{str_val:.2f}\"\n",
    "    \n",
    "    print(f\"{metric:<25} {bh_str:<15} {str_str:<15}\")\n",
    "\n",
    "# Calculate information ratio (excess return / tracking error)\n",
    "excess_returns = spy_data['Strategy_Return'] - spy_data['Log_Return']\n",
    "information_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252) if excess_returns.std() > 0 else 0\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Information Ratio: {information_ratio:.2f}\")\n",
    "print(f\"Correlation with B&H: {spy_data['Strategy_Return'].corr(spy_data['Log_Return']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trading strategy performance\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 14))\n",
    "\n",
    "# Plot 1: Cumulative returns comparison\n",
    "axes[0].plot(spy_data.index, spy_data['Buy_Hold_Cumulative'], \n",
    "            label='Buy & Hold', linewidth=2, color='blue', alpha=0.8)\n",
    "axes[0].plot(spy_data.index, spy_data['Strategy_Cumulative'], \n",
    "            label='HMM Strategy', linewidth=2, color='red', alpha=0.8)\n",
    "\n",
    "axes[0].set_title('Cumulative Returns Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Cumulative Return')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add performance annotations\n",
    "final_bh = spy_data['Buy_Hold_Cumulative'].iloc[-1] - 1\n",
    "final_strategy = spy_data['Strategy_Cumulative'].iloc[-1] - 1\n",
    "axes[0].text(0.02, 0.98, f'Buy & Hold: {final_bh:.1%}\\nHMM Strategy: {final_strategy:.1%}', \n",
    "            transform=axes[0].transAxes, verticalalignment='top', \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Plot 2: Position sizes over time\n",
    "axes[1].fill_between(spy_data.index, 0, spy_data['Position'], \n",
    "                    where=(spy_data['Position'] > 0), color='green', alpha=0.6, label='Long Position')\n",
    "axes[1].fill_between(spy_data.index, 0, spy_data['Position'], \n",
    "                    where=(spy_data['Position'] < 0), color='red', alpha=0.6, label='Short Position')\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "axes[1].set_title('Position Sizes Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Position Size')\n",
    "axes[1].set_ylim(-1.1, 1.1)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Rolling performance comparison (6-month rolling)\n",
    "window = 126  # ~6 months\n",
    "rolling_bh = spy_data['Log_Return'].rolling(window).sum()\n",
    "rolling_strategy = spy_data['Strategy_Return'].rolling(window).sum()\n",
    "\n",
    "axes[2].plot(spy_data.index, rolling_bh, label='Buy & Hold (6M Rolling)', \n",
    "            linewidth=1.5, color='blue', alpha=0.7)\n",
    "axes[2].plot(spy_data.index, rolling_strategy, label='HMM Strategy (6M Rolling)', \n",
    "            linewidth=1.5, color='red', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "axes[2].set_title('6-Month Rolling Returns Comparison', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('6-Month Return')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Performance by regime\n",
    "print(\"\\nüìà STRATEGY PERFORMANCE BY REGIME:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for regime_name in regime_names:\n",
    "    mask = spy_data['Regime_Name'] == regime_name\n",
    "    if mask.sum() > 0:\n",
    "        regime_bh = spy_data.loc[mask, 'Log_Return']\n",
    "        regime_strategy = spy_data.loc[mask, 'Strategy_Return']\n",
    "        \n",
    "        print(f\"\\n{regime_name} Regime ({mask.sum()} days):\")\n",
    "        print(f\"  Buy & Hold: {regime_bh.sum():.3f} ({regime_bh.mean()*252:.1%} annualized)\")\n",
    "        print(f\"  HMM Strategy: {regime_strategy.sum():.3f} ({regime_strategy.mean()*252:.1%} annualized)\")\n",
    "        print(f\"  Excess Return: {(regime_strategy.sum() - regime_bh.sum()):.3f}\")\n",
    "        \n",
    "        avg_position = spy_data.loc[mask, 'Position'].mean()\n",
    "        print(f\"  Average Position: {avg_position:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Validation and Robustness\n",
    "\n",
    "It's crucial to validate our HMM results and test robustness. Let's perform some diagnostic tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation and diagnostics\n",
    "print(\"üîç MODEL VALIDATION AND DIAGNOSTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Convergence analysis\n",
    "if hasattr(hmm, 'training_history_') and 'log_likelihoods' in hmm.training_history_:\n",
    "    log_likelihoods = hmm.training_history_['log_likelihoods']\n",
    "    \n",
    "    print(f\"\\nüìä CONVERGENCE ANALYSIS:\")\n",
    "    print(f\"  Iterations: {len(log_likelihoods)}\")\n",
    "    print(f\"  Initial log-likelihood: {log_likelihoods[0]:.2f}\")\n",
    "    print(f\"  Final log-likelihood: {log_likelihoods[-1]:.2f}\")\n",
    "    print(f\"  Improvement: {log_likelihoods[-1] - log_likelihoods[0]:.2f}\")\n",
    "    \n",
    "    # Check if model converged\n",
    "    if len(log_likelihoods) > 5:\n",
    "        recent_improvement = log_likelihoods[-1] - log_likelihoods[-5]\n",
    "        if abs(recent_improvement) < 1e-3:\n",
    "            print(\"  ‚úÖ Model appears to have converged\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Model may not have fully converged (recent improvement: {recent_improvement:.4f})\")\n",
    "\n",
    "# 2. Residual analysis\n",
    "print(f\"\\nüß™ RESIDUAL ANALYSIS:\")\n",
    "\n",
    "# Calculate standardized residuals for each regime\n",
    "standardized_residuals = []\n",
    "residual_regimes = []\n",
    "\n",
    "for i, regime_idx in enumerate(regime_order):\n",
    "    regime_mask = spy_data['Regime'] == regime_idx\n",
    "    if regime_mask.sum() > 0:\n",
    "        regime_returns = spy_data.loc[regime_mask, 'Log_Return']\n",
    "        regime_mean = means[regime_idx, 0]\n",
    "        regime_std = np.sqrt(covariances[regime_idx, 0, 0])\n",
    "        \n",
    "        residuals = (regime_returns - regime_mean) / regime_std\n",
    "        standardized_residuals.extend(residuals.tolist())\n",
    "        residual_regimes.extend([regime_names[i]] * len(residuals))\n",
    "        \n",
    "        print(f\"  {regime_names[i]} Residuals:\")\n",
    "        print(f\"    Mean: {residuals.mean():.4f} (should be ~0)\")\n",
    "        print(f\"    Std: {residuals.std():.4f} (should be ~1)\")\n",
    "        print(f\"    Skewness: {residuals.skew():.3f}\")\n",
    "        print(f\"    Kurtosis: {residuals.kurtosis():.3f}\")\n",
    "\n",
    "# 3. Model comparison with different numbers of states\n",
    "print(f\"\\nüîÑ MODEL COMPARISON (Different # of States):\")\n",
    "\n",
    "model_comparison = []\n",
    "for n_states in [2, 3, 4]:\n",
    "    try:\n",
    "        print(f\"  Training {n_states}-state model...\")\n",
    "        test_hmm = HiddenMarkovModel(n_states=n_states, random_state=42)\n",
    "        test_hmm.fit(returns_array)\n",
    "        \n",
    "        # Calculate AIC and BIC\n",
    "        if hasattr(test_hmm, 'training_history_') and 'final_log_likelihood' in test_hmm.training_history_:\n",
    "            log_likelihood = test_hmm.training_history_['final_log_likelihood']\n",
    "        else:\n",
    "            log_likelihood = test_hmm.score(returns_array)  # Fallback\n",
    "        \n",
    "        # Number of parameters: transition matrix + emission parameters\n",
    "        n_params = n_states * (n_states - 1) + n_states * 2  # transitions + means + variances\n",
    "        n_obs = len(returns_array)\n",
    "        \n",
    "        aic = 2 * n_params - 2 * log_likelihood\n",
    "        bic = np.log(n_obs) * n_params - 2 * log_likelihood\n",
    "        \n",
    "        model_comparison.append({\n",
    "            'n_states': n_states,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'n_params': n_params,\n",
    "            'aic': aic,\n",
    "            'bic': bic\n",
    "        })\n",
    "        \n",
    "        print(f\"    Log-likelihood: {log_likelihood:.2f}\")\n",
    "        print(f\"    AIC: {aic:.2f}\")\n",
    "        print(f\"    BIC: {bic:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Failed to train {n_states}-state model: {e}\")\n",
    "\n",
    "# Determine best model\n",
    "if model_comparison:\n",
    "    best_aic = min(model_comparison, key=lambda x: x['aic'])\n",
    "    best_bic = min(model_comparison, key=lambda x: x['bic'])\n",
    "    \n",
    "    print(f\"\\n  üèÜ Best model by AIC: {best_aic['n_states']} states (AIC: {best_aic['aic']:.2f})\")\n",
    "    print(f\"  üèÜ Best model by BIC: {best_bic['n_states']} states (BIC: {best_bic['bic']:.2f})\")\n",
    "\n",
    "# 4. Out-of-sample validation\n",
    "print(f\"\\nüìÖ OUT-OF-SAMPLE VALIDATION:\")\n",
    "\n",
    "# Split data: use first 80% for training, last 20% for testing\n",
    "split_idx = int(len(returns_array) * 0.8)\n",
    "train_returns = returns_array[:split_idx]\n",
    "test_returns = returns_array[split_idx:]\n",
    "test_dates = spy_data.index[split_idx:]\n",
    "\n",
    "print(f\"  Training period: {spy_data.index[0].date()} to {spy_data.index[split_idx-1].date()}\")\n",
    "print(f\"  Testing period: {spy_data.index[split_idx].date()} to {spy_data.index[-1].date()}\")\n",
    "print(f\"  Training samples: {len(train_returns)}\")\n",
    "print(f\"  Testing samples: {len(test_returns)}\")\n",
    "\n",
    "try:\n",
    "    # Train model on training data only\n",
    "    oos_hmm = HiddenMarkovModel(n_states=3, random_state=42)\n",
    "    oos_hmm.fit(train_returns)\n",
    "    \n",
    "    # Test on out-of-sample data\n",
    "    oos_states = oos_hmm.predict(test_returns)\n",
    "    oos_probs = oos_hmm.predict_proba(test_returns)\n",
    "    \n",
    "    # Calculate out-of-sample log-likelihood\n",
    "    oos_log_likelihood = oos_hmm.score(test_returns)\n",
    "    in_sample_log_likelihood = oos_hmm.score(train_returns)\n",
    "    \n",
    "    print(f\"  In-sample log-likelihood: {in_sample_log_likelihood:.2f}\")\n",
    "    print(f\"  Out-of-sample log-likelihood: {oos_log_likelihood:.2f}\")\n",
    "    print(f\"  Difference: {oos_log_likelihood - in_sample_log_likelihood:.2f}\")\n",
    "    \n",
    "    # Check if similar regime patterns are detected\n",
    "    oos_regime_dist = np.bincount(oos_states) / len(oos_states)\n",
    "    is_regime_dist = np.bincount(spy_data['Regime'][:split_idx]) / split_idx\n",
    "    \n",
    "    print(f\"  \\n  Regime distribution comparison:\")\n",
    "    for i in range(3):\n",
    "        print(f\"    State {i}: In-sample {is_regime_dist[i]:.2%}, Out-of-sample {oos_regime_dist[i]:.2%}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Out-of-sample validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize diagnostics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Model Diagnostics and Validation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Convergence plot\n",
    "if hasattr(hmm, 'training_history_') and 'log_likelihoods' in hmm.training_history_:\n",
    "    log_likelihoods = hmm.training_history_['log_likelihoods']\n",
    "    axes[0, 0].plot(log_likelihoods, 'b-', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Convergence')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Log-Likelihood')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight final iterations\n",
    "    if len(log_likelihoods) > 10:\n",
    "        axes[0, 0].plot(range(len(log_likelihoods)-5, len(log_likelihoods)), \n",
    "                       log_likelihoods[-5:], 'ro-', markersize=4, label='Final 5 iterations')\n",
    "        axes[0, 0].legend()\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'Convergence data\\nnot available', \n",
    "                   ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "    axes[0, 0].set_title('Model Convergence (Data Not Available)')\n",
    "\n",
    "# Plot 2: Standardized residuals\n",
    "if standardized_residuals:\n",
    "    axes[0, 1].hist(standardized_residuals, bins=30, density=True, alpha=0.7, color='skyblue')\n",
    "    \n",
    "    # Overlay normal distribution for comparison\n",
    "    x = np.linspace(-4, 4, 100)\n",
    "    axes[0, 1].plot(x, scipy.stats.norm.pdf(x), 'r-', linewidth=2, label='Standard Normal')\n",
    "    \n",
    "    axes[0, 1].set_title('Standardized Residuals Distribution')\n",
    "    axes[0, 1].set_xlabel('Standardized Residual')\n",
    "    axes[0, 1].set_ylabel('Density')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Model comparison\n",
    "if model_comparison:\n",
    "    n_states_list = [m['n_states'] for m in model_comparison]\n",
    "    aic_values = [m['aic'] for m in model_comparison]\n",
    "    bic_values = [m['bic'] for m in model_comparison]\n",
    "    \n",
    "    axes[1, 0].plot(n_states_list, aic_values, 'bo-', linewidth=2, markersize=8, label='AIC')\n",
    "    axes[1, 0].plot(n_states_list, bic_values, 'ro-', linewidth=2, markersize=8, label='BIC')\n",
    "    axes[1, 0].set_title('Model Selection Criteria')\n",
    "    axes[1, 0].set_xlabel('Number of States')\n",
    "    axes[1, 0].set_ylabel('Information Criterion')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_xticks(n_states_list)\n",
    "\n",
    "# Plot 4: Q-Q plot of residuals\n",
    "if standardized_residuals:\n",
    "    from scipy import stats\n",
    "    stats.probplot(standardized_residuals, dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title('Q-Q Plot: Residuals vs Normal')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of diagnostics\n",
    "print(f\"\\nüéØ DIAGNOSTIC SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if hasattr(hmm, 'training_history_') and 'log_likelihoods' in hmm.training_history_:\n",
    "    log_likelihoods = hmm.training_history_['log_likelihoods']\n",
    "    if len(log_likelihoods) > 5:\n",
    "        recent_improvement = log_likelihoods[-1] - log_likelihoods[-5]\n",
    "        convergence_status = \"‚úÖ Converged\" if abs(recent_improvement) < 1e-3 else \"‚ö†Ô∏è May need more iterations\"\n",
    "        print(f\"Model Convergence: {convergence_status}\")\n",
    "\n",
    "if standardized_residuals:\n",
    "    residual_mean = np.mean(standardized_residuals)\n",
    "    residual_std = np.std(standardized_residuals)\n",
    "    print(f\"Residual Quality: Mean={residual_mean:.3f}, Std={residual_std:.3f}\")\n",
    "    \n",
    "    # Normality test\n",
    "    from scipy.stats import jarque_bera\n",
    "    jb_stat, jb_pvalue = jarque_bera(standardized_residuals)\n",
    "    normality_status = \"‚úÖ Normal\" if jb_pvalue > 0.05 else \"‚ö†Ô∏è Non-normal\"\n",
    "    print(f\"Residual Normality: {normality_status} (JB p-value: {jb_pvalue:.4f})\")\n",
    "\n",
    "if model_comparison:\n",
    "    best_aic = min(model_comparison, key=lambda x: x['aic'])\n",
    "    best_bic = min(model_comparison, key=lambda x: x['bic'])\n",
    "    if best_aic['n_states'] == best_bic['n_states']:\n",
    "        print(f\"Optimal Model: ‚úÖ {best_aic['n_states']} states (consistent across AIC/BIC)\")\n",
    "    else:\n",
    "        print(f\"Model Selection: AIC suggests {best_aic['n_states']} states, BIC suggests {best_bic['n_states']} states\")\n",
    "\n",
    "print(f\"\\nüí° Overall Assessment:\")\n",
    "print(f\"The 3-state HMM appears to capture market regime dynamics reasonably well.\")\n",
    "print(f\"Consider the diagnostic results when interpreting trading signals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps and Advanced Topics\n",
    "\n",
    "Congratulations! You've successfully implemented and analyzed a Hidden Markov Model for financial market regime detection. Here are some advanced topics and next steps to consider:\n",
    "\n",
    "### üöÄ Advanced Techniques\n",
    "1. **Online Learning**: Use `OnlineHMM` for real-time regime detection\n",
    "2. **Multivariate Models**: Include volume, volatility, and other features\n",
    "3. **Non-Gaussian Emissions**: Use Student-t distributions for fat tails\n",
    "4. **Change Point Detection**: Identify structural breaks in regime behavior\n",
    "\n",
    "### üìä Enhanced Trading Strategies\n",
    "1. **Dynamic Position Sizing**: Adjust leverage based on regime uncertainty\n",
    "2. **Multi-Asset Models**: Detect regime correlations across asset classes\n",
    "3. **Risk Management**: Implement regime-specific stop-losses and risk limits\n",
    "4. **Portfolio Construction**: Build regime-aware portfolios\n",
    "\n",
    "### üî¨ Further Validation\n",
    "1. **Monte Carlo Testing**: Test strategy robustness with synthetic data\n",
    "2. **Cross-Validation**: Use time series cross-validation techniques\n",
    "3. **Alternative Models**: Compare with other regime detection methods\n",
    "4. **Transaction Costs**: Include realistic trading costs in backtests\n",
    "\n",
    "Let's create a quick preview of online learning capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview of Online HMM capabilities\n",
    "print(\"üîÑ PREVIEW: ONLINE LEARNING WITH STREAMING DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize Online HMM\n",
    "config = OnlineHMMConfig(\n",
    "    n_states=3,\n",
    "    forgetting_factor=0.98,  # How quickly to forget old data\n",
    "    adaptation_rate=0.05,    # How quickly to adapt parameters\n",
    "    window_size=252,         # Rolling window size\n",
    "    min_observations=50      # Minimum observations before predictions\n",
    ")\n",
    "\n",
    "online_hmm = OnlineHMM(config)\n",
    "\n",
    "print(f\"‚úÖ Online HMM initialized with config:\")\n",
    "print(f\"  States: {config.n_states}\")\n",
    "print(f\"  Forgetting factor: {config.forgetting_factor}\")\n",
    "print(f\"  Adaptation rate: {config.adaptation_rate}\")\n",
    "\n",
    "# Simulate streaming data processing\n",
    "print(f\"\\nüîÑ Simulating streaming data processing...\")\n",
    "\n",
    "# Use first part of data to initialize\n",
    "init_size = 100\n",
    "streaming_results = []\n",
    "\n",
    "try:\n",
    "    # Initialize with batch of data\n",
    "    init_returns = returns.iloc[:init_size].values\n",
    "    online_hmm.fit(init_returns.reshape(-1, 1))\n",
    "    \n",
    "    print(f\"‚úÖ Initialized with {init_size} observations\")\n",
    "    \n",
    "    # Process remaining data one observation at a time\n",
    "    for i in range(init_size, min(init_size + 50, len(returns))):\n",
    "        new_return = returns.iloc[i]\n",
    "        \n",
    "        # Add new observation\n",
    "        online_hmm.update(new_return)\n",
    "        \n",
    "        # Get current regime info\n",
    "        regime_info = online_hmm.get_current_regime_info()\n",
    "        \n",
    "        streaming_results.append({\n",
    "            'date': spy_data.index[i],\n",
    "            'return': new_return,\n",
    "            'regime': regime_info.get('most_likely_regime', 'Unknown'),\n",
    "            'confidence': regime_info.get('confidence', 0),\n",
    "            'regime_probs': regime_info.get('regime_probabilities', [0, 0, 0])\n",
    "        })\n",
    "        \n",
    "        if i % 10 == 0:  # Print every 10th observation\n",
    "            date_str = spy_data.index[i].strftime('%Y-%m-%d')\n",
    "            regime = regime_info.get('most_likely_regime', 'Unknown')\n",
    "            conf = regime_info.get('confidence', 0)\n",
    "            print(f\"  {date_str}: Regime {regime} (confidence: {conf:.1%})\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Processed {len(streaming_results)} streaming observations\")\n",
    "    print(f\"\\nüí° Online HMM allows for:\")\n",
    "    print(f\"  ‚Ä¢ Real-time regime detection as new data arrives\")\n",
    "    print(f\"  ‚Ä¢ Adaptive parameters that evolve with market conditions\")\n",
    "    print(f\"  ‚Ä¢ Memory-efficient processing of long time series\")\n",
    "    print(f\"  ‚Ä¢ Immediate trading signals without retraining\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Online HMM demo encountered an issue: {e}\")\n",
    "    print(f\"This is normal - Online HMM requires more complex initialization\")\n",
    "    print(f\"See the dedicated Online HMM tutorial for full implementation\")\n",
    "\n",
    "print(f\"\\nüìö To learn more about Online HMM:\")\n",
    "print(f\"  ‚Ä¢ Check out the 'Online HMM Streaming Demo' notebook\")\n",
    "print(f\"  ‚Ä¢ Read the Online HMM documentation\")\n",
    "print(f\"  ‚Ä¢ Explore real-time trading applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Summary and Key Takeaways\n",
    "\n",
    "In this tutorial, we've covered the complete workflow for using Hidden Markov Models in financial markets:\n",
    "\n",
    "### ‚úÖ What We Accomplished\n",
    "1. **Loaded and analyzed** real market data (SPY from 2020-2024)\n",
    "2. **Trained a 3-state HMM** to detect Bull, Bear, and Sideways regimes\n",
    "3. **Interpreted model parameters** and regime characteristics\n",
    "4. **Implemented regime detection** using Viterbi and Forward-Backward algorithms\n",
    "5. **Built a trading strategy** based on regime classifications\n",
    "6. **Validated the model** using multiple diagnostic techniques\n",
    "7. **Compared performance** against buy-and-hold strategy\n",
    "\n",
    "### üéØ Key Insights\n",
    "- **Market regimes are real**: Our model detected economically meaningful regime patterns\n",
    "- **HMMs capture persistence**: Regimes show realistic duration and transition patterns\n",
    "- **Trading applications**: Regime-based strategies can provide risk management benefits\n",
    "- **Model validation is crucial**: Always validate your models before deployment\n",
    "\n",
    "### ‚ö†Ô∏è Important Disclaimers\n",
    "- **Past performance ‚â† Future results**: Historical backtests may not predict future performance\n",
    "- **Transaction costs matter**: Real trading involves costs not included in this analysis\n",
    "- **Model risk exists**: HMMs make assumptions that may not hold in all market conditions\n",
    "- **Professional advice recommended**: Consult financial professionals before implementing strategies\n",
    "\n",
    "### üîó Next Steps\n",
    "1. **Explore other tutorials** in this series\n",
    "2. **Experiment with different assets** and time periods\n",
    "3. **Try advanced features** like Online HMMs and multivariate models\n",
    "4. **Implement proper risk management** in any trading applications\n",
    "\n",
    "### üìñ Additional Resources\n",
    "- Mathematical Foundations documentation\n",
    "- Online HMM streaming tutorial\n",
    "- Trading applications guide\n",
    "- Configuration and tuning documentation\n",
    "\n",
    "---\n",
    "\n",
    "**Happy modeling! üöÄüìà**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}