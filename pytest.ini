[tool:pytest]
# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output options
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --color=yes
    --durations=10
    --showlocals
    --disable-warnings

# Coverage options
addopts = 
    --cov=hidden_regime
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-branch
    --cov-fail-under=80

# Minimum version requirement
minversion = 7.0

# Markers for test categorization
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (slower, requires components)
    performance: Performance and benchmark tests (slow)
    slow: Slow running tests
    network: Tests that require network access
    models: Tests related to HMM models
    data: Tests related to data loading and processing
    config: Tests related to configuration
    utils: Tests for utility functions
    regression: Regression tests for previously fixed bugs

# Test timeout (in seconds)
timeout = 300

# Ignore warnings from external packages
filterwarnings =
    ignore::UserWarning:yfinance.*
    ignore::FutureWarning:pandas.*
    ignore::DeprecationWarning:matplotlib.*
    ignore::PendingDeprecationWarning:scipy.*
    ignore::RuntimeWarning:numpy.*
    # Ignore specific warnings that we know about
    ignore:.*divide by zero encountered.*:RuntimeWarning
    ignore:.*invalid value encountered.*:RuntimeWarning
    ignore:.*The 'nopython' keyword.*:NumbaWarning

# Log configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test collection options
collect_ignore = [
    "setup.py",
    "build",
    "dist",
    ".eggs",
    "docs",
    ".git",
    ".pytest_cache",
    "__pycache__"
]

# Parallel test execution (when pytest-xdist is installed)
# addopts = -n auto

# Performance testing options (when pytest-benchmark is installed)
# benchmark-only: Only run benchmark tests
# benchmark-skip: Skip benchmark tests
# benchmark-sort: Sort benchmark results by mean time
# benchmark-min-rounds: Minimum number of rounds to run each benchmark
# benchmark-warmup: Disable warmup rounds for faster testing